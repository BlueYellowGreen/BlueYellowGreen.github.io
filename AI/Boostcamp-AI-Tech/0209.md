---
title: 02/09 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 02/09 Summary
  - property: og:title
    content: 02/09 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 02/09 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0209.html
---

### 2022/02/09, 새로 알게된 점

<p class="tags">#Transformer</p>

&nbsp; 기다리던 <span style="color: #2454ff;">**Transformer**</span> 시간이다!

#### Transformer

::: details Transformer Image
Transformer 관련한 모든 Image 는 [Jay Alammar GitHub](https://jalammar.github.io/illustrated-transformer/)속 Image 를 사용하였다.
:::

&nbsp; Transformer 는 기본적으로 sequential data 를 다루는 방법론이다. 어제 배운 RNN, LSTM, GRU 과는 다른 방법론이지만 해결하려고 하는 문제는 비슷하다. 
sequential data 를 다루는 어려움에 대해서 다시 언급하자면, 

- Original sequence &nbsp; &#10140; &nbsp; sequential data 가 들어올 때,
- Trimmed sequence  &nbsp; &#10140; &nbsp; 길이가 달라질 수도 있고,
- Omitted sequence  &nbsp; &#10140; &nbsp; 중간 data 가 빠질 수도 있고,
- Permuted sequence  &nbsp; &#10140; &nbsp; data 가 밀리는? 경우도 있다.

이러한 문제가 있어서, 위에 해당하는 data 를 이용하여 RNN 같이 sequential 하게 입력이 들어가는 모델링은 무척이나 어렵다. 
그래서 이러한 문제를 해결하고자 Transformer 를 개발했던 것 같고, <span style="color: #2454ff;">**self-attention**</span> 을 사용한다는 특징이 있다. 

&nbsp; Transformer 는 **"Attention is All You Need"**, NIPS, 2017 에 GOOGLE 이 발표한 논문 속 모델이다. 
Transformer 는 기본적으로 sequential 한 데이터를 인코딩하는 방법이기 때문에, <span style="color: #2454ff;">**NMT**</span> 
(Neural Machine Translation; 기계어 번역) 문제 뿐만 아니라, <span style="color: #2454ff;">**classification**</span>, 
<span style="color: #2454ff;">**detection**</span>, ... 등 다양하게 적용된다. 

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/01.png?raw=true">

&nbsp; 우리가 하려고 하는 것은, 문장이 주어지면 다른 언어로 바꾸는 것이다 (seq2seq). 
기존의 RNN을 사용하면 sequential data 길이만큼 재귀적으로 동작하지만, transformer 는 data 길이에 상관없이 
<span style="color: #2454ff;">**한 번에 입력**</span>을 받고, 인코딩 과정을 거친다. 물론 generation 할 때는 autoregressive 하게 
동작한다 (한 단어씩 만듬). 그리고 일반적으로 <span style="color: #2454ff;">**동일한 개수의 인코더와 디코더 레이어**</span>를 쌓는다. 

&nbsp; transformer 에서 반드시 알아야 하는 내용은 다음과 같다. **첫 번째**, 어떻게 인코더에 한 번에 입력하는지를 알아야 하고, 
**두 번째**, 마지막 인코더 레이어와 각각의 디코더들이 어떠한 <span style="color: #2454ff;">**정보**</span>를 주고받는지 알아야 하며, 
**세 번째**, 마지막 디코더 레이어가 어떻게 <span style="color: #2454ff;">**generation**</span> 할 수 있는지 알아야 한다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/02.png?raw=true">

<br>

<hr>

### 피어 세션

<br>

<br>

<br>

<style scoped>
.tags { color: #2454ff; }
a { color: #2454ff; }
</style>