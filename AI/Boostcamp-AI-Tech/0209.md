---
title: 02/09 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 02/09 Summary
  - property: og:title
    content: 02/09 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 02/09 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0209.html
---

### 2022/02/09, 새로 알게된 점

<p class="tags">#Transformer</p>

&nbsp; 기다리던 <span style="color: #2454ff;">**Transformer**</span> 시간이다!

#### Transformer

::: details Transformer Image
Transformer 관련한 모든 Image 는 [Jay Alammar GitHub](https://jalammar.github.io/illustrated-transformer/)속 Image 를 사용하였다.
:::

&nbsp; Transformer 는 기본적으로 sequential data 를 다루는 방법론이다. 어제 배운 RNN, LSTM, GRU 과는 다른 방법론이지만 해결하려고 하는 문제는 비슷하다. 
sequential data 를 다루는 어려움에 대해서 다시 언급하자면, 

- Original sequence &nbsp; &#10140; &nbsp; sequential data 가 들어올 때,
- Trimmed sequence  &nbsp; &#10140; &nbsp; 길이가 달라질 수도 있고,
- Omitted sequence  &nbsp; &#10140; &nbsp; 중간 data 가 빠질 수도 있고,
- Permuted sequence  &nbsp; &#10140; &nbsp; data 가 밀리는? 경우도 있다.

이러한 문제가 있어서, 위에 해당하는 data 를 이용하여 RNN 같이 sequential 하게 입력이 들어가는 모델링은 무척이나 어렵다. 
그래서 이러한 문제를 해결하고자 Transformer 를 개발했던 것 같고, <span style="color: #2454ff;">**self-attention**</span> 을 사용한다는 특징이 있다. 

&nbsp; Transformer 는 **"Attention is All You Need"**, NIPS, 2017 에 GOOGLE 이 발표한 논문 속 모델이다. 
Transformer 는 기본적으로 sequential 한 데이터를 인코딩하는 방법이기 때문에, <span style="color: #2454ff;">**NMT**</span> 
(Neural Machine Translation; 기계어 번역) 문제 뿐만 아니라, <span style="color: #2454ff;">**classification**</span>, 
<span style="color: #2454ff;">**detection**</span>, ... 등 다양하게 적용된다. 

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/01.png?raw=true">

&nbsp; 우리가 하려고 하는 것은, 문장이 주어지면 다른 언어로 바꾸는 것이다 (seq2seq). 
기존의 RNN을 사용하면 sequential data 길이만큼 재귀적으로 동작하지만, transformer 는 data 길이에 상관없이 
<span style="color: #2454ff;">**한 번에 입력**</span>을 받고, 인코딩 과정을 거친다. 물론 generation 할 때는 autoregressive 하게 
동작한다 (한 단어씩 만듬). 그리고 일반적으로 <span style="color: #2454ff;">**동일한 개수의 인코더와 디코더 레이어**</span>를 쌓는다. 

&nbsp; transformer 에서 반드시 알아야 하는 내용은 다음과 같다. **첫 번째**, 어떻게 인코더에 한 번에 입력하는지를 알아야 하고, 
**두 번째**, 마지막 인코더 레이어와 각각의 디코더들이 어떠한 <span style="color: #2454ff;">**정보**</span>를 주고받는지 알아야 하며, 
**세 번째**, 마지막 디코더 레이어가 어떻게 <span style="color: #2454ff;">**generation**</span> 할 수 있는지 알아야 한다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/02.png?raw=true">

&nbsp; 첫 번째로 입력 관련 내용이다. 한 번에 N 개의 sequential data 가 인코더 입력으로 들어간다는 것이다. 
하나의 인코더는 <span style="color: #2454ff;">**Self-Attention**</span> 과 
<span style="color: #2454ff;">**Feed Forward Neural Network**</span> 를 **한 번씩** 거치는 구조이다. 
그리고 출력되어 나오는 N 개의 값이 두 번째 인코더 레이어의 입력으로 들어간다. 

중요한 점은 **Self-Attention** 이다. Transformer 의 성능이 좋도록 만드는 핵심이라는데, Attention 이 무엇이길래?

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/03.png?raw=true">

&nbsp; 예시를 들어보자, N 개의 단어가 들어간다고 했는데 예시에서는 3개의 단어가 들어간다고 가정해보자. 
그리고 기본적으로 기계가 번역할 수 있게 하기 위해서 <span style="color: #2454ff;">**단어마다 특정 숫자의 벡터로 표현(embedding)**</span>하게 된다. 
즉, 3개의 vector 가 입력으로 들어간다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/04.png?raw=true">

&nbsp; 그러면 인코더 레이어 속 Self-Attention 이 3개의 벡터를 3개의 <span style="color: #2454ff;">**feature vector**</span> 로 만든다. 
N 개가 들어오면 N 개의 feature vector 로 만드는 것이다.
vector &#10140; vector 이 과정을 feed forward 로 볼 수도 있지만, 다른 중요한 점이라면 $X_1$ vector 가 $Z_1$ vector 로 될 때, 
단순히 $X_1$ vector 정보만 활용하는 것이 아니라 $X_2$, $X_3$ 정보까지 <span style="color: #2454ff;">**같이 활용**</span>한다. 
그래서 Self-Attention 은 <span style="color: #2454ff;">**dependency**</span> 가 있다. 

그 다음에 만나는 feed forward 네트워크는 각각의 vector 에 대해서 dependency 가 없다. 단순히 통과시키며 변화시키는 것에 불과하다. 

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/06.png?raw=true">

&nbsp; 영어 문장 "The animal didn't cross the street because it was too tired." 에서 it 의 의미를 찾는 과정을 Transformer 가 해준다. 
**it** 이라는 단어를 인코딩 할 때, 다른 단어들과의 관계성을 보게되고, 가장 관계가 높은 단어가 무엇인지 알아서 학습한다. 
그러다보니 단어를 더 잘 표현할 수 있다 (이해할 수 있다).

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/05.png?raw=true">

더 살펴보기 전에 문제를 단순히 하기 위해서, 3개의 단어가 아닌 2개의 단어가 입력되었다고 생각해보자. 

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/07.png?raw=true">

&nbsp; Self-Attention 구조는 3가지 vector 를 만들어낸다. 3개의 vector 를 만들어내는 것은, 3개의 Neural Network 있다고 보면 된다. 
해당 vector 들은 각각 <span style="color: #2454ff;">**Query**</span>, <span style="color: #2454ff;">**Key**</span>, 그리고 
<span style="color: #2454ff;">**Value**</span> 이다. 그래서 <span style="color: #2454ff;">**각각의 단어마다 Q, K, V vector**</span> 가 있다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/08.png?raw=true">

&nbsp; 이 3개의 vector 를 통해서 우리가 $x_1$ 이라고 부르는 embedding vector 를 새로운 vector 로 바꿔줄 것이다. 
먼저 <span style="color: #2454ff;">**Score vector**</span> 를 만든다. Thinking 이라는 첫 번째 단어에 대한 Score vector 를 계산할 때, 
**인코딩을 하고자 하는 vector** 의 <span style="color: #2454ff;">**Query vector**</span> 와 
**자기 자신을 포함한 모든 N 개의 vector** 에 대한 <span style="color: #2454ff;">**Key vector**</span> 를 구한다. 
그리고 그 두 개의 vector 를 <span style="color: #2454ff;">**내적**</span> (inner product) 한다. 
그러면 이 두 vector 가 얼마나 잘 align 되어 있는지 (나머지 단어들과 얼마나 유사도가 있는지, 관계가 있는지) 정한다.

&nbsp; 내적한 것이 결국은 i 번째 vector 와 나머지 vector 사이에 얼마나 interact 해야하는지 알아서 학습하게한다. 이것이 Attention 이다. 
즉, 특정 task 를 수행할 때 어떤 입력을 주의 깊게 볼지 정하는 것이다. 그 다음 과정은 단순하다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/09.png?raw=true">

&nbsp; Score vector 가 나오면 <span style="color: #2454ff;">**normalize**</span> 한다. Normalize 시 <span style="color: #2454ff;">**8**</span>로 
나눠주는데, 이 숫자는 **Key vector 의 차원**에 연관이 있다. 우리가 Key vector 의 차원을 얼만큼 할지 **하이퍼파라미터**로 정하는 것이다. 
위의 예시에서는 64개의 vector 로 만들었고, $\sqrt{64}$ 를 통해 나온 숫자이다. Score 값이 적정 범위를 유지하도록 하는 것이다. 

&nbsp; 결과적으로, <u><span style="color: #2454ff;">**Key vector 의 차원과 Query vector 의 차원이 같아**</span></u>야 내적을 할 수 있고, 
내적 값을 Key vector 의 차원으로 나눠 normalize 한다. 
그리고 <span style="color: #2454ff;">**softmax**</span> 를 취한다. 결과 값 0.88 의 의미는, Thnking 단어가 자기 자신과 attention 에 대한의 interation 의 
값이라는 것이다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/10.png?raw=true">

&nbsp; 각각의 단어의 Score 는 scala 값인데, 이를 <span style="color: #2454ff;">**Value vector**</span> 에 곱함으로써 weights 에 **가중치**를 더한다. 
Value vector 는 차원이 달라도 된다 ( <span style="color: #2454ff;">**하지만 편의상 같게 만든다**</span> ). 
그리고 최종적으로 나오는 Thinking 이라는 인코딩된 vector 의 차원은 **value vector 의 차원과 동일**하다. 

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/11.png?raw=true">

&nbsp; 말로 설명해서 복잡하지만, 행렬을 이용하여 계산하는 과정은 간단하다.<br>
위 그림에서 $X$ 의 shape 이 (2, 4) 인데, 2는 **단어의 개수**를 의미하고, 각 단어마다 4차원으로 표현한다는 의미이다. 
그리고 3개의 Weight (about Query, Key, Value) 와 $X$ 와의 곱으로 Q, K, V vector 를 구하는데, 단어가 2개이므로 `shape[0]=2` 가 된다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/12.png?raw=true">

&nbsp; 그런 다음 Query vector 와 Key vector 를 내적해서 나온 값을 Key vector 차원으로 normalize 한 뒤 softmax 를 취하고, 
해당 scalar 값을 Value vector 에 weight sum 하면 Self-Attention 부분은 끝난다. TensorFlow 나 PyTorch 에서는 1~2 줄로 구현할 수 있다.

&nbsp; 그러면 왜 이러한 방식이 잘 될까?<br>
Input 형태가 고정된 기존 모델과는 달리, flexible 하게 input 을 받을 수 있고, 이로 인해 더 많은 것을 표현할 수 있어서이지 않나 싶다. 
다만 Input 인 embedding vector 길이가 길어질 수록 **메모리 부담**이 커지게 된다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/13.png?raw=true">

&nbsp; 이번에는 <span style="color: #2454ff;">**MHA**</span> (Multi-headed attention) 이다.<br>
별건 없고, 위에서 길게 설명한 Attention 과정을 **여러번 하는 것**이다. 한 개의 embedding vector 에 대해서 여러개의 Query, Key, Value vector 를 만든다고 보면 된다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/14.png?raw=true">

&nbsp; 이를 통해서 N 개의 인코딩된 vector 를 얻게 된다 (위 예시에서는 8개). 다만 문제라면, 하나의 인코더 레이어를 통해 나온 인코딩 벡터가 
다음 인코더 레이어로 들어가기 때문에, <span style="color: #2454ff;">**입력 - 출력 차원을 맞춰줄 필요**</span>가 있다. 
즉, embedding vector 와 인코딩 vector 의 차원이 같아야 한다.

&nbsp; MHA 를 통해 N 개의 인코딩 vector 가 나왔으니까 linear 하게 이어붙이면, 
차원은 <span style="color: #2454ff;">**( 단어의 개수, embedding 차원 x MHA 횟수(N) )**</span> 이다. 
이를 embedding vector 의 차원으로 축소시키려면 <span style="color: #2454ff;">**( embedding 차원 x MHA 횟수(N), embedding 차원 )**</span> 크기로 곱하면 된다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/15.png?raw=true">

전반적인 과정은 위의 그림과 같다. 하지만 실제 코드를 이렇게 구현하지 않았다. 
MHA 를 linear 하게 합치는 것이 아니라, <u>**embedding vector 의 차원을 MHA 개수로 나눈 것으로 진행**</u>한다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/16.png?raw=true">

&nbsp; 그런 다음 <span style="color: #2454ff;">**Positional Encoding**</span> 이 추가된다. 입력에 특정한 값을 더해주는 것으로써, 
<span style="color: #2454ff;">**bias**</span> 라고 생각하면 된다. 그런데 이 과정이 왜 필요할까? 이전의 과정을 돌이켜보면, Attention 으로 
단어와의 관계를 학습했지만 그 속에 <span style="color: #2454ff;">**순서 정보는 없다**</span>. 그래서 순서에 대한 정보를 더하기 위해 
positional encoding 을 더한다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/17.png?raw=true">
<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/18.png?raw=true">

Positional Encoding 은 특정 방법으로 만들게 된다. 4차원인 경우이고, 논문에서는 512차원이었다. 최근에는 두 번째 그림과 같이 적용한다고 한다. 
이후의 과정은 다른 모델들과 크게 다를 바가 없다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/19.png?raw=true">
<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/20.png?raw=true">

Self-Attetion 으로 N 개의 단어가 주어지면, N 개의 인코딩 vector $Z$ 가 나오고 Layer Normalization 과정을 거친다. 

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/21.png?raw=true">

&nbsp; 그런 다음 Feed Forward 를 거친다. 이 과정이 반복된다.<br>
인코딩 과정은 단어를 표현하는 것이었고 이를 통해 <span style="color: #2454ff;">**디코더가 생성**</span>해야 한다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/22.gif?raw=true">

&nbsp; 그래서 두 번째로 디코더가 받는 정보 부분이다.<br>
마지막 인코더는 각각의 디코더에 <span style="color: #2454ff;">**Key**</span> 와 <span style="color: #2454ff;">**Value**</span> 를 보낸다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/23.gif?raw=true">

&nbsp; 최종 출력은 autoregressive 하게 한 단어씩 만든다.<br>
그런데 i 번째 단어를 만들 때, 모든 문장을 다 알고 있으면 학습 의미가 없으므로, 학습 단계에서 <span style="color: #2454ff;">**Masking**</span> 을 하게 된다. 
Masking 의 의미는, 이전 단어들에 대해서만 연관이 있고, 뒤에 있는 단어들에 대해서는 독립적으로 만드는 것을 말한다.

<br>

<img src="https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/transformer/24.png?raw=true">

마지막 layer 에서 단어들의 분포를 만들어서, 매번 그 중에서 단어를 샘플링하는 방식으로 동작하게 된다.

<br>

여기까지 알아본 Transformer 는 사실 NMT 문제에서만 사용되었었는데, 점차 시간이 지나며 단어들의 sequence 를 다루는 것 뿐만이 아니라, 
<span style="color: #2454ff;">**이미지에서도 활용**</span>하고있다.

<span style="color: #2454ff;">**Vision Transformer**</span> &nbsp; &#10140; &nbsp; [**논문**](https://arxiv.org/abs/2010.11929)

이미지 분류를 할 때 인코더만 활용한다. 그리고 인코더에서 나오는 첫 번째 encoded vector 를 classifier 에 입력하는 구조이다. 
NMT 에서는 문장이 입력되었다면, 이미지에서는 일정 구간으로 나눠 이를 입력시켰다. 마찬가지로 positional encoding 이 들어간다.

<br>

그리고 문장이 주어지면 문장에 대한 이미지를 만들어내는 **DALL-E** 도 있다. openai 에서 말하길, transformer 에서 **디코더**만 활용했고, 
이미지를 16x16 ? grid 로 나눠 sequencial 하게 입력하고 문장도 입력해서, 새로운 문장이 주어졌을 때 그 문장에 대한 이미지를 만든다고 한다.

<span style="color: #2454ff;">**DALL-E**</span> &nbsp; &#10140; &nbsp; [**openai**](https://openai.com/blog/dall-e)

<br>

<hr>

### 피어 세션

<br>

<br>

<br>

<style scoped>
.tags { color: #2454ff; }
a { color: #2454ff; }
</style>