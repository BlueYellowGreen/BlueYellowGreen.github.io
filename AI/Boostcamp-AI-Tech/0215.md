---
title: 02/15 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 02/15 Summary
  - property: og:title
    content: 02/15 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 02/15 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0215.html
---

### 2022/02/15, 새로 알게된 점

<p class="tags">#mlfow #서비스_모델_개발 #저작권</p>

&nbsp; MLflow 가 없던 시절에는 Jupyter Notebook 에서 주로 코드를 작성하고, 학습한 모델에 대한 Parameter, Metric 을 따로 기록해두는 방식으로 진행했다. 
그리고 학습을 통해 나온 Weight File 을 다른 사람에게 공유하기도 하였다. 이러한 일련의 과정을 개선하고 싶었고, 또한 학습 과정 중 종종 겪는 OOM 
( Out of Memory ) 오류로 인해 중간 과정을 제대로 기록하지 못하는 것을 극복하고 싶었다. 

즉, **실험을 추적**하고, **코드를 재현**할 수 있으며, 모델을 **패키징** 및 **배포** 과정을 쉽게 하며, 
그리고 모델을 쉽게 **관리**할 수 있는 전반적인 프로세스를 구축하고 싶었다.<br>
&#10140; &nbsp; <span style="color: #2454ff;">**MLflow**</span>

머신러닝 **실험** 및 **배포**를 쉽게 관리할 수 있는 **오픈소스**가 나오게 되었다. 상용 소프트웨어 중에서는 유사한 제품들이 많지만, 
오픈소스 대비 빠르게 성장중이다. **CLI**, **GUI** ( localhost:5000 ) 환경 모두 지원하며, 사용 방법도 간편하다.

```python
...
import mlflow
...


def main():
    # 학습 autologging
    mlflow.autolog(log_input_examples=True)

    # 데이터 처리
    ...

    # 모델 학습
    model = Model()
    with mlflow.start_run() as run:
        model.fit(X, y)
        print(f'Log: {run.info.run_id}')


if __name__ == '__main__':
    main()
```

<br>

### MLflow 핵심 기능

1. **Experiment Management & Tracking**

    - 머신러닝 관련 실험들을 관리하고, 각 실험의 내용들을 기록 ( 여러 사람이 하나의 MLflow 서버에 공유 가능 )
    - 실험을 정의하고, 실험을 실행할 수 있다. ( 실행 - 머신러닝 훈련 코드를 실행한 기록 )
    - 각 실행에 사용한 소스코드, 하이퍼파라미터, Metric 등을 저장

<br>

2. **Model Registry**

    - MLflow 로 실행한 머신러닝 모델을 Model Registry 에 등록 가능
    - 모델 저장소에 모델이 저장될 때마다 해당 모델의 버전이 자동으로 올라감
    - Model Registry 에 등록된 모델은 다른 사람에게 쉽게 공유 가능

<br>

3. **Model Serving**

    - Model Registry 에 등록한 모델을 **REST API** 형태의 서버로 Serving 할 수 있음
    - Input = Model 의 Input
    - Output = Model 의 Output
    - 직접 Docker Image 를 만들지 않아도 생성할 수 있음

<br>

### MLflow Component

- **MLflow Tracking**
    - 머신러닝 코드를 실행한다. 로깅을 위한 API 및 UI 를 제공한다.
    - MLflow Tracking 결과를 Local 및 Server 에 기록해서 다른 기록/실행과 비교할 수 있다.
    - 팀에서는 팀원과 결과 비교 방식으로 협업을 진행하 수 있다.

<br>

- **MLflow Project**
    - 머신러닝 코드를 패키징하기 위한 표준이다.
    - **Project** &nbsp; &#10140; &nbsp; 간단하게 소스 코드가 저장된 폴더로, Git Repo 와 유사하다. 의존성과 어떻게 실행해야 하는지 등이 저장된다.
    - MLflow Tracking API 를 사용하면 MLflow 는 프로젝트 버전에 대해 모든 파라미터를 자동으로 로깅한다.

<br>

- **MLflow Model**
    - 모델은 모델 파일과 코드로 저장된다. (pickle 파일?)
    - 다양한 플랫폼에 배포할 수 있는 여러 도구를 제공한다.
    - MLflow Tracking API 를 사용하면 MLflow 는 자동으로 해당 프로젝트에 대한 내용을 사용한다.

<br>

- **MLflow Registry**
    - MLflow Model 전체 Lifecycle 에서 사용할 수 있는 중앙 모델 저장소이다.

<br>

### MLflow 사용

1. MLflow 설치

가상환경 하에서,

```bash
pip install mlflow
```

<br>

2. 실험 생성

&nbsp; MLflow 에서는 제일 먼저 **Experiment** 를 생성해야 한다. 여기서 하나의 Experiment 는 **진행하고 있는 머신러닝 프로젝트 단위**를 말한다. 
그런 다음, 정해진 **Metric** ( RMSE, MSE, MAE, Accuracy, ... ) 로 모델을 **평가**한다. 그리고 하나의 Experiment 는 여러 Run ( 실행 ) 을 가질 수 있다. 

```bash
# Experiment 생성
mlflow experiments create --experiment-name my-first-experiment
```

위 명령어를 실행하면 현재 경로에 <span style="color: #2454ff;">**mlruns**</span> 라는 폴더가 생긴다. 
여기에는 Run 에 대한 기록을 담고 있다.

다음의 명령어를 통해 Experiment 리스트를 확인할 수 있다.

```bash
mlflow experiments list
```

<br>

3. 코드 작성

&nbsp; 필요한 라이브러리를 설치 후, 폴더를 생성하여 그곳에서 머신러닝 코드를 작성한다.

```python
# Parameter 및 Metric 관리 / autologging 이 나오기 전 방식
mlflow.log_param('parameter_name_1', param_1)
mlflow.log_param('parameter_name_2', param_2)
mlflow.log_metric('score', score)
mlflow.sklearn.log_model(model_name, 'model')
```

**autolog**

- **모든 프레임워크에서 사용 가능한 것은 아니다**. (MLflow 에서 지원해주는 것만 가능)
    - pytorch.nn.Module 은 지원하지 않음 (Pytorch Lightning 은 지원)
- autolog 와 **하이퍼파라미터 튜닝**도 같이 할 수 있다.

<br>

**MLflow Project**

&#10140; MLflow 를 사용한 코드의 프로젝트 메타 정보를 저장한다. 프로젝트를 어떤 환경에서 어떻게 실행시킬지를 정의하며, 패키지 모듈의 상단에 위치한다. 
파일을 꼭 <span style="color: #2454ff;">**MLProject**</span> 라는 이름으로 사용해야 한다. (고정된 이름)

<br>

4. MLflow Project

MLProject 를 생성한다.

```bash
vi project_name/MLProject
```

MLProject 파일의 내용의 형태는 다음과 같다.

```text
name: tutorial

entry_points:
    main:
        command: "python train.py"
```

<br>

5. MLflow Tracking - Run

&nbsp; 이제 Run 을 통해 학습을 시킨다. 하나의 Run 은 코드를 1번 실행한 것을 의미하고, 이 Run 은 모델 학습 코드를 실행시키는 것을 말한다. 
즉, 한 번의 학습 실행을 통해 하나의 Run 이 생성되고, 학습 과정 속 내용들이 기록된다. 

Run 에서 로깅하는 것들은 다음과 같다.

- Source &nbsp; &#10140; &nbsp; 실행한 Project 이름
- Version &nbsp; &#10140; &nbsp; 실행 Hash
- Start & end time
- Parameters
- Metrics &nbsp; &#10140; &nbsp; 모델의 평가 지표로, Metrics 을 시각화할 수 있다.
- Tags &nbsp; &#10140; &nbsp; 관련된 Tag 들이다.
- Artifacts &nbsp; &#10140; &nbsp; 실행 과정에서 생기는 다양한 파일들을 말한다. (이미지, 모델 Pickle ...)

Run 은 다음의 명령어로 실행시킬 수 있다.

```bash
mlflow run project_name --experiment-name my-first-experiment --no-conda
```

&nbsp; 실행한 기록을 확인하기 위해 다음의 명령어를 입력한다.

```bash
mlflow ui
```

그러게 되면, 5000번 포트가 비어있을 경우 해당 포트로 MLflow UI 웹 페이지에 접속할 수 있다.

Experiment 와 Run 의 관계를 말하자면 둘 다 여러개를 가질 수 있는데, **여러개의 Run 이 하나의 Experiment 에 포함되는 관계**이다.

<br>

### MLflow 서버로 배포하기

MLflow Architecture 는 크게 3가지로 나뉠 수 있다.

- **파이썬 코드** (with MLflow package)
    - 모델을 만들고 학습하는 코드
    - mlflow run 으로 실행

```python
...
def main():
    mlflow.sklearn.autolog()

    ...
    clf = GridSearchCV(svc, parameters)

    with mlflow.start_run() as run:
        clf.fit(X, y)


if __name__ == '__main__':
    main()
```

<br>

- **Tracking Server**
    - 파이썬 코드가 실행되는 동안 Parameter, Metric, Model 등 메타 정보 저장
    - 파일 혹은 **DB**에 저장

MLflow Tracking Server 와 외부 Storage 를 사용하려면 `mlflow server` 명령어로 Backend Store URI 를 지정해야 한다.

```bash
mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root $(pwd)/artifacts
```

이렇게 하면 아무것도 저장되지 않은 서버가 (localhost:5000) 생긴다.<br>
그 다음으로 **환경 변수**를 지정해야 한다.

```bash
export MLFLOW_TRACKING_URI="http://127.0.0.1:5000"
```

그런 다음 Experiments 를 생성한 후 Run 하면, 환경 변수에 저장된 곳으로 MLflow 데이터가 들어간다. 

<br>

- **Artifact Store**
    - 파이썬 코드가 실행되는 동안 생기는 Model File, Image 등의 아티팩트를 저장
    - 파일 혹은 **스토리지**에 저장

<br>

#### MLflow 실제 활용 사례

실제 회사에서는 MLflow Tracking Server 하나로 운영한다.<br>
Tracking Server 하나 배포하고, 팀 내 모든 Researcher 가 이 Tracking Server 에 실험을 기록한다. 
배포할 때는 Docker Image, Kubernetes 등에 진행할 수도 있고 다른 방법을 사용할 수도 있다.

이런 방식으로 진행하므로, 로그나 모델이 한 곳에 저장되어, 팀 내 모든 실험을 공유할 수 있다. 
그리고 Artifact Storage 와 DB 역시 하나로 운영하는데, Artifact Storage 는 **GCS** 나 **S3** 같은 스토리지를 이용하고, 
DB 는 **CloudSQL** 이나 **Aurora RDS** 같은 DB 를 사용한다. 
이 두 저장소는 Tracking Server 에 의해 관리된다. 

<br>

### 서비스향 AI 모델 개발

**연구 관점**

&#10140; &nbsp; **정해진** 데이터셋 / 평가 방식에서 **더 좋은 모델**을 찾는다.

**서비스 관점**

&#10140; &nbsp; 학습 데이터셋도 없고 (대부분), 테스트 데이터셋과 테스트 방법도 없다. 대신 서비스 요구 사항만 있다. 
그래서 **학습 데이터셋을 준비**해야 한다. 정확히는, 서비스 요구사항으로 부터 학습 데이터셋의 
<span style="color: #2454ff;">**종류/수량/정답**</span>을 정해야 한다 (어려운 일이다).

그런 다음 요구사항에 맞는 **입출력**을 갖는 **서비스 모듈**을 개발해야 한다. 
그런데 데이터 입력 과정에서 어려움이 발생한다면, 해당 **문제를 해결하기 위한 기술 모듈**도 추가되어야 한다. 

결국 학습 데이터 준비하려면 모델 파이프 라인 설계가 되어 있어야 하고, 모델 파이프 라인 설계하려면 어느 정도 데이터가 있어야 한다. (??) 
이 과정을 반복해서 수렴해간다..

<br>

파트별로 보통 겪게 되는 일은 다음과 같다.

- **서비스 기획자**
    - 기능 요구사항 구체화
    - 학습 데이터 수량/종류 논의

- **AI 모델 개발자**
    - AI 모델 설계 논의
    - 학습 데이터 정답/수량/종류 논의

- **학습 데이터셋 준비 담당자**
    - 외주 업체와의 커뮤니케이션을 통해,
    - 작업 가이드 작성
    - 작업 단가 논의
    - 작업 수량 논의
    - QnA 대응

- **외주 업체**
    - 작업 툴 개발

<br>

그렇다면 테스트 데이터셋 / 테스트 방법 준비는..?

보통 테스트 데이터셋은 학습 데이터셋에서 일부 사용한다고 하고(?), 서비스 요구사항으로부터 테스트 방법을 도출해야 한다. 
실 서비스 전, **개발 환경**에서의 정량 평가와 **실 서비스 적용 시**의 정량 평가는 이질감이 굉장히 클 수 있다. 
결국, 서비스에서의 품질이 중요하기 때문에 OFFLINE 테스트 결과가 ONLINE 테스트 결과와 유사하게 OFFLINE 테스트를 설계해야 한다. 

그래서 테스트 방법에 대해 다음처럼 정리할 수 있다.

- **OFFLINE**
    - 정량 평가 &nbsp; &#10140; &nbsp; 완벽하지 않기 때문에 <span style="color: #2454ff;">**AI 모델 후보 선택 목적**</span>으로 활용
    - 정성 평가 &nbsp; &#10140; &nbsp; 각 후보 AI 모델에 대한 <span style="color: #2454ff;">**면밀 분석**</span> 후 서비스 출시 버전 선택
- **ONLINE**
    - 정량 평가 &nbsp; &#10140; &nbsp; 해당 AI 모델을 서비스 시나리에서 <span style="color: #2454ff;">**자동 정량 평가**</span>
    - 정성 평가 &nbsp; &#10140; &nbsp; <span style="color: #2454ff;">**VOC**</span> (Void Of Customer). AI 모델 개선 포인트 파악 (가장 중요)

<br>

추가로, 모델에 관련한 요구사항을 도출해야 한다.

- **처리 시간**
    - 하나의 입력이 처리되어 출력이 나올 때까지의 시간 (OFFLINE / ONLINE 관점 다를 수 있음)

- **목표 정확도**
    - 해당 기술 모듈의 정량적인 정확도 (OFFLINE / ONLINE 관점이 다를 수 있음)

- **목표 qps**
    - QPS (Queries Per Second) - 초당 처리 가능한 요청 수
    - 향상 방법
        - 장비를 늘린다 &#10140; N 대 늘리면 QPS 도 대략 N 배 올라가지만 (비용...)
        - 처리 시간을 줄인다 &#10140; 처리 속도가 N 배 올라가면 QPS 도 N 배 올라간다.
        - 모델 크기를 줄인다 &#10140; 한 GPU 에 올라가는 모델 수가 N 배가 되면 QPS 도 N 배 올라간다.
    
- **Serving 방식**
    - 기술 모듈이 Mobile 에서 동작하기 원하는지
    - Local CPU/GPU Server 에서 동작하기 원하는지
    - Cloud CPU/GPU Server 에서 동작하기 원하는지

- **장비 사양**
    - 가끔은 Serving 장비조차 없어서 장비 구축까지 같이 요구하기도 한다. 이럴 경우 예산/QPS 에 맞춰서 장비 사양도 정해야 한다.

<br>

### 내 AI 모델은 합법일까

> Upstage 문지형 님의 자료를 인용하였습니다.

&nbsp; 좋은 AI 모델은 좋은 데이터로부터 나온다.<br>
문제를 풀기 위해 모델을 만들기 위해서는 데이터가 있어야 한다. 하지만 대부분의 경우 적합한 데이터가 없고, 그러다보니 
데이터를 제작할 때 <span style="color: #2454ff;">**저작권**</span>을 고려하지 않으면 합법적으로 사용할 수 없다. 
동일선상으로, 합법적이지 않은 데이터로 학습한 모델 또한 합법적이라고 보기 어렵다.

현재의 저작권법은 아직 AI 모델 개발을 고려하지 않은 부분이 있다.

- **저작권법 제1조 (목적)**
    - 이 법은 **저작자의 권리와 이에 인접하는 권리를 보호**하고 **저작물의 공정한 이용을 도모**함으로써 **문화 및 관련 산업의 향상발전에 이바지함**을 목적으로 한다.

그래서 AI 분야 저작권 면책조항이 신설된 저작권법 개정안이 추진되고 있다. 따라서, AI 와 창작자 모두를 고려한 좋은 방향의 법 개정을 위해 관심을 가질 필요가 있다.

그렇다면 **저작원**이 무엇일까?<br>
&#10140; 사람의 생각이나 감정을 표현한 결과물(저작물)에 대하여 창작자에게 주는 권리로 "창작성"이 있다면 별도의 등록절차없이 자연히 발생한다.

위에서 언급한 **저작물**에는 다음의 종류들이 있다.

- 소설, 시, 논문, 강연, 연설, 각본 그 밖의 어문저작물
- 음악저작물
- 연극 및 무용, 무언극 그 밖의 연극저작물
- 회화, 서예, 조각, 판화, 공예, 응용미술저작물 그 밖의 미술저작물
- 건축물, 건축을 위한 모형 및 설계도서 그 밖의 건축저작물
- 사진저작물(이와 유사한 방법으로 제작된 것을 포함한다)
- 영상저작물
- 지도, 도표, 설계도, 약도, 모형 그 밖의 도형저작물
- 컴퓨터프로그램저작물

반대로 저작권법에 의해 **보호받지 못하는 저작물**도 있다.

- 헌법, 법률, 조약, 명령, 조례 및 규칙
- 국가 또는 지방자치단체의 고시, 공고, 훈령 그 밖에 이와 유사한 것
- 법원의 판결, 결정, 명령 및 심판이나 행정심판절차 그 밖에 이와 유사한 절차에 의한 의결, 결정 등
- 국가 또는 지방자치단체가 작성한 것으로서 제1호 내지 제3호에 규정된 것의 편집물 또는 번역물
- 사실의 전달에 불과한 시사보도

<br>

그래서 이제부터, 창작성이 인정되는 저작물에 저작권이 자연발생할 경우 어떻게 데이터를 **합법적**으로 쓸 수 있는지 알아보자.

1. **저작자와 협의한다.**
    - 저작물 이용을 허락받거나, 저작재산권을 양수받는 것 등의 방법
    - **독점적** 이용허락
        - 데이터에 대한 "독점적"인 권리를 행사하는 것을 허락
    - **비독점적** 이용허락
        - 저작자는 계약을 체결한 이용자 외에도 데이터 이용 계약을 맺을 수 있다.
    - 저작재산권 **전부/일부**에 대한 양도
        - 저작재산권은 양도할 수 있는 권리로, 저작물을 이용하려는 사람은 타인의 저작재산권을 양수받아서 이용 가능하다.
        - 모든/일부 저작재산권을 양도받을 수 있으며, 일정한 기간을 정하여 양수받을 수도 있다.

그런데 이렇게 일일이 계약을 맺는 방식은 비효율적일 것 같다. 더 좋은 방법이 있을까?<br>
&#10140; **라이센스**

2. **라이센스**
    - 저작자에게 이용 허가 요청을 하지 않아도 저작자가 제안한 특정 조건을 만족하면 이용이 가능하도록 만든 저작물에 대한 **이용허락 규약**
    - 라이센스를 발행하는 단체는 다양할 수 있다.
        - 가장 유명한 것은 Creative Commons 라는 비영리 단체에서 제공하는 <span style="color: #2454ff;">**CCL**</span>
        - 국내에는 문화체육관광부에서 제공하는 <span style="color: #2454ff;">**공공누리**</span>가 있다.

<br>

#### Creative Commons License (CCL)

종류는 크게 6가지로 볼 수 있다. 

- CC-**BY**
- CC-BY-**ND**
- CC-BY-**SA**
- CC-BY-**NC**
- CC-BY-NC-ND
- CC-BY-NC-SA

여기서 CC 는 Creative Commons 를 의미하고, 공통적으로 사용되는 단어의 뜻은 다음과 같다.

**BY** &nbsp; &#10140; &nbsp; 저작자표시 ( 적절한 출처와, 해당 라이센스 링크를 표시하고, 변경이 있는 경우 공지 )<br>
**ND** &nbsp; &#10140; &nbsp; 변경금지 ( 저작물을 리믹스, 변형하거나 2차적 저작물을 작성하였을 경우 그 결과물을 공유할 수 없음 )<br>
**NC** &nbsp; &#10140; &nbsp; 비영리 ( 영리 목적으로 이용할 수 없고, 교육과 연구 등 비영리 목적만 가능 )<br>
**SA** &nbsp; &#10140; &nbsp; 동일조건변경허락 ( 저작물을 리믹스, 변형하거나 2차적 저작물을 작성하고 결과물을 공유할 경우 <span style="color: #2454ff;">**동일한**</span> CCL 을 적용 )

<br>

대부분의 뉴스 기사는 저작권법에 보호를 받고 있어서 개인적으로 연락을 통해 허락을 받아야 한데, 위키트리의 경우 **CC-BY-SA** 라이센스로 사용 가능하다! 
또한, **뉴스 제목은 저작권법에 보호받지 않아 자유롭게 사용**해도 된다.

그리고 <span style="color: #2454ff;">**공정 이용**</span> ( Fair-use ) 라고 해서, 아래의 경우에 대해서는 저작권자의 허락을 받지 않고도 저작물을 이용할 수 있다.

- 교육
- 재판절차 등에서의 복제
- 정치적 연설 등의 이용
- 학교 교육 목적 등에의 이용
- 시사 보도를 위한 이용
- 공표된 저작물의 이용
- 영리를 목적으로 하지 않은 공연, 방송
- 사적 이용을 위한 복제
- 도서관 등에서의 복제
- 시험 문제로서의 복제
- 시각장애인 등을 위한 복제
- 방송사업가의 일시적 녹음, 녹화
- 미술, 사진, 건축저작물의 전시 또는 복제
- 번역 등에 의한 이용
- 시사적인 기사 및 논설의 복제
- 프로그램 코드 역분석
- 정당한 이용자에 의한 보존을 위한 프로그램 복제



<br>

<br>

<style scoped>
.tags { color: #2454ff; }
.img-to-center { display:block; margin: 0 auto; }
a { color: #2454ff; }
</style>