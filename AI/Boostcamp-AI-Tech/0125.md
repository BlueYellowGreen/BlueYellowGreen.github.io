---
title: 01/25 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 01/25 Summary
  - property: og:title
    content: 01/25 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 01/25 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0125.html
---

### 2022/01/25, 새로 알게된 점

<p class="tags">#Module #Parameter #AutoGrad #Dataset #DataLoader #HuggingFace #Albumentations</p>

&nbsp; 오늘은 학습을 위한 데이터 부분, Dataset & DataLoader 에 관하여 학습하였다. 
그 전에, 어제 배웠던 AutoGrad 에 대해서 다시 보자.

#### AutoGrad

&nbsp; 먼저 PyTorch 에서는 `torch.nn.Module` 이라는 큰 자유를 준다. 
이곳에 원하는 방식으로, 마치 레고를 조립하듯이 쌓아나갈 수 있다. 
정확하게는, 딥러닝을 구성하는 레이어의 base class 이다. 
그래서 Input / Output / Forward / Backward 로 정의되는데, 여기서 Backward 가 AutoGrad 로 자동 미분이 일어난다.

&nbsp; 레이어에 포함되어 있는 Parameter 클래스 객체인 Weights 가 학습의 대상이 되어, 
`forward()` 의 결과값과 실제 값 간의 차이 **Loss** 에 대해 미분을 수행하여 그라디언트를 계산하고, 
`step()` 시 이를 각각 파라미터의 `.grad` 에 저장한다.

&nbsp; Backward 는 module 단계에서 직접 개발이 가능하다. backward와 optimizer 를 오버라이딩하면 되지만, 
그렇게 되면 직접 미분 수식을 써야한다. 그래서 새로운 구조를 개발하는 것이 아닌 이상 직접 개발하는 일은 드물다.

#### Dataset & DataLoader

![Dataset-DataLoader](https://github.com/BlueYellowGreen/BlueYellowGreen.github.io/blob/main/.vuepress/public/assets/img/Dataset-DataLoader.png?raw=true)

&nbsp; PyTorch 의 data handling 관련 구조는 위의 그림과 같다. 
**Dataset** 에서 **데이터의 정보, 길이, 데이터를 어떻게 불러올 것인지**에 대한 내용이 반드시 포함되어 있어야 한다. 
그리고 일반적으로 데이터 학습을 시키기 위해 Tensor 형태로 바꿔줘야 하는데, 이 작업은 주로 
**transforms** 에서 이루어진다.

&nbsp; transforms 는 간단한 전처리부터 시작해서 데이터 증강 기법까지 다루는데, CV 라면 torchvision.transform 에 NLP 라면 
torchtext 에 해당 함수들을 이용한다. 내장 함수 이외에도, 이미지 처리를 위해 <span style="color: #2454ff;">**Albumentations**</span> 라이브러리를 
많이 사용하기도 한다. NLP 에서는 데이터 증강까진 아니지만 Backbone 모델 및 다양한 데이터를 <span style="color: #2454ff;">**HuggingFace**</span> 에서 얻는다.

&nbsp; DataLoader의 경우 제작한 Dataset 클래스로 만든 인스턴스를 이용하여 만들어지는 generator 이다. 
그러다보니, 방대한 양의 데이터가 있어도 하드웨어 자원에 맞게 batch 학습을 돌릴 수 있다. 
DataLoader 에서 중요한 기능은 <span style="color: #2454ff;">**sampler**</span> 와 <span style="color: #2454ff;">**collate_fn**</span> 을 들 수 있다.

&nbsp; `sampler` 는 shuffle=False 일 때 사용할 수 있는 기능으로, 데이터를 어떻게 뽑을지 인덱스 설정에 관한 것이다. 
주로 불균형 데이터에서 고른 비율로 데이터를 선별할 때 사용된다.

&nbsp; `collate_fn` 는 추가적인 데이터 처리 작업에 관한 것으로 batch 단위로 적용된다.<br>
Dataset 의 `__getitem()__` 이나 transforms 로 처리하면 되지 않을까 하는 생각이 들지만, 이들은 모두 데이터 **독립적**으로 개별마다 적용된다. 
즉, 다른 데이터와의 상호작용을 기대할 수 없는데, **collate_fn** 의 경우 **batch 단위**의 데이터들에 대해 서로 접근이 가능하다는 차이가 있다. 
그래서 주로 Data 와 Label 이 쌍으로 묶여 있는 dataset 에 대해서 따로 따로 **분리**를 시켜주거나, 
다양한 길이의 텍스트에 대해 0 으로 패딩을 줘 고른 길이로 만드는 등에 주로 사용된다. (NLP 영역)

<br>

<hr>

### 피어 세션

오늘도 역시나 과제가 상당하다.

하나 하나 내용이 매우 알차다보니 소화시키는데 다소 걸릴 것 같다.

사실상 이번 주 학습 내용이 PyTorch 전반에 관한 사용법을 다루다보니 이것을 잘만 익혀내도, 
추후에 논문을 코드로 구현해내거나, 다른 사람의 코드를 해석하는데 무리가 없을 것 같다.

<br>

<br>

<br>

<style scoped>
.tags { color: #2454ff; }
a { color: #2454ff; }
</style>