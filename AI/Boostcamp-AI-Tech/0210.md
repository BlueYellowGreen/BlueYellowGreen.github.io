---
title: 02/10 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 02/10 Summary
  - property: og:title
    content: 02/10 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 02/10 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0210.html
---

### 2022/02/10, 새로 알게된 점

<p class="tags">#generative_model</p>

#### Generative Model

&nbsp; 기본적인 Generative Model 구조가 어떻게 되는지, 트렌드는 어떠한지 알아보자.
Generative Model 은 무엇일까? 생성 모델이라고 떠오르지만, 생성하는 것을 넘어서서 많은 것을 담고 있다. 강아지로 예시를 들어보면,
강아지처럼 생긴($x_{new}$) 샘플을 샘플링 (**generation**; $x_{new}\sim p(x)$) 하는 것을 할 수도 있고, 
<span style="color: #2454ff;">**Density estimation**</span> 을 할 수 있다. 이것은 <span style="color: #2454ff;">**anomaly detection**</span> (이상치 감지) 
에 적용될 수 있다. 그리고 데이터의 특징을 학습한다 (Unsupervised representation learning; <span style="color: #2454ff;">**feature learning**</span>).

&nbsp; 그래서, generative model 을 학습한다는 것은 단순히 <span style="color: #2454ff;">**생성**</span>해내는 것 뿐만 아니라 
<span style="color: #2454ff;">**구분**</span>도 할 수 있다는 것이다. 이러한 모델을 <span style="color: #2454ff;">**explicit**</span> model 이라고 부른다. 
<u>**입력이 주어졌을 때 확률 값을 얻어낼 수 있는 모델**</u>이다. 반대로 생성만 할 수 있는 모델은 inplicit model 이라고 한다.

그렇다면 $p(x)$ 를 어떻게 만들까? 이를 위해선 확률에 관한 지식이 필요하다.


**Basic Discrete Distributions**

- **Bernoulli distribution** &nbsp; &#10140; &nbsp; 0 or 1

    - $P(X=0)\;=\;p\quad\text{then}\quad P(X=1)\;=\;1-p$

    - $X\sim\text{Ber}(p)$ 라고 표현한다.

- **Categorical distribution** &nbsp; &#10140; &nbsp; N

    - $P(Y=i)\;=\;p_i\quad\text{such that}\quad\sum_{i=1}^{m}p_i\;=\;1$

    - $Y\sim\text{Cat}(p_1,\dots,p_m)$ 라고 표현한다.

<br>

&nbsp; RGB 로 예시를 들어보자.<br>
RGB 를 표현하면 $(r,g,b)\sim p(R,G,B)$ (joint distribution) 이고, $256 \times 256 \times 256$ 클래스를 갖는다. 
이것을 표현하려면 $256 \times 256 \times 256 - 1$ 개의 파라미터가 필요하다. 하나의 픽셀을 표현하기 위해 어마어마하게 필요하다..

&nbsp; RGB 는 너무 크니 binary (0, 1) pixel 를 표현해보자.
$n$ 개의 pixel 은 $2 \times 2 \times\dots\times2\;=\;2^n$ 경우가 존재한다. 이에 필요한 파라미터 수는 $2^n-1$ 이다. 이것도 많다. 
기계학습에서 파라미터가 많을 수록 학습하기 어려운데 말이다.

&nbsp; 여전히 $n$ 개의 pixel 을 표현하고 싶어서 파라미터를 줄여야 한다. 그러기 위해서 $n$ 개의 pixel 이 다 독립적이라고 가정하자.
사실 인접 픽셀은 연관되겠지만 말이다. 그래도 여전히 경우의 수는 $2^n$ 이지만, 이 distribution 을 표현하기 위해서는 
<span style="color: #2454ff;">**$n$**</span> 개의 파라미터만 있으면 된다!<br>
왜? 각각의 pixel 이 독립적이니깐, 더하면 된다!

&nbsp; 그런데 이 가정은 극단적이라 표현할 수 있는 정보가 별로 없다. 그래서 그 중간을 찾고 싶었다. 그래서 나온 것이 
<span style="color: #2454ff;">**Conditional Independence**</span> 개념이다. 그 중간을 위해 다음 3가지 규칙이 사용된다.

- **Chain rule**

    $$p(x_1,\dots,x_n)\;=\;p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\dots p(x_n|x_1,\dots,x_{n-1})$$

- **Bayes' rule**

    $$p(x|y)\;=\frac{p(x,y)}{p(y)}\;=\;\frac{p(y|x)p(x)}{p(y)}$$

- **Conditional independence**

    $$\text{if}\;x\;\bot\;y\;|\;z,\;\text{then}\;p(x|y,z)\;=\;p(x|z)$$

    - $z$ 가 주어졌을 때, $x$ 와 $y$ 가 independent 하다. (가정)

    - 그러면 $z$ 라는 random variable 이 주어졌을 때, $x$ 와 $y$ 가 independent 하니깐, 
    $x$ 라는 random variable 을 표현하는데 있어서 <span style="color: #2454ff;">**$y$ 는 상관이 없다**</span>.

<br>

이제 다시 파라미터를 따져보자.<br>
우선 Chain rule 만 이용하여 따져본다면 바뀔까? 다른 추가된 가정이 없는데 말이다.

- first pixel &nbsp; &#10140; &nbsp; $p(x_1)$ - 첫 pixel 은 1개의 파라미터로 표현할 수 있다.

- second pixel &nbsp; &#10140; &nbsp; $p(x_2|x_1)$ - 두 번째 pixel 은 2개의 파라미터가 필요하다.
    - $p(x_2|x_1=0)$ - $x_1$ 이 주어졌을 때 $x_2$ 이 0인 확률과, $p(x_2|x_1=1)$ - $x_1$ 이 주어졌을 때 $x_2$ 이 1인 확률

- third pixel &nbsp; &#10140; &nbsp; $p(x_3|x_1,x_2)$ - 세 번째 pixel 은 4개의 파라미터가 필요하다.

- 그러므로, $1+2+2^2+\dots+2^{n-1}\;=\;2^n-1$ 로 동일하다. 즉, 이전과 같다.

<br>

이제는 Conditional Independence 와 관련된 가정을 추가해보자 ( <span style="color: #2454ff;">**Markov assumption**</span> ).

$$\text{Markov assumption}\;:\quad \text{suppose}\;X_{i+1}\;\bot\;X_1,...,X_{i-1}|X_i\quad\text{then}\quad$$

$$p(x_1,...,x_n)\;=\;p(x_1)p(x_2|x_1)p(x_3|x_2)\dots p(x_n|x_{n-1})$$

<span style="color: #2454ff;">**i+1 번째 pixel 은 i 번째 pixel 에만 연관**</span>되어 있다는 가정이다. 
이것을 표현하기 위해 필요한 파라미터는 $\color{blue}{2n-1}$ 이다.

단순히 chain rule 로 쪼갠 것만 가지고는 파라미터 수의 변동이 없었지만, 쪼갠 뒤 Markov 가정을 적절히 적용하니 파라미터 개수를 줄일 수 있었다!
이러한 방법을 <span style="color: #2454ff;">**Auto-regressive model**</span> 이라고 부르고, **conditional independency** 하다.

<br>

&nbsp; 이제 Auto-regressive Model 을 살펴보자.<br>
$28\times28$ binary pixels 로 이루어진 MNIST 를 생각해보자. 우리가 하려는 것은 확률분포 $p(x)$ 를 구하는 것이다. 
여기에 활용하는 것은 Auto-regressive Model 로 Chain rule 을 가지고 Joint Distribution 을 나누어 사용해보려고 한다.
explicit, inplicit model 모두 살펴볼 것이다. 

그러면 이 $p(x)$ 를 어떻게 표현할 수 있을까? 말했던 것처럼 Chain rule 을 가지고 나누자.

$$p(x_{1:784})\;=\;p(x_1)p(x_2|x_1)p(x_3|x_{1:2})\dots$$

&nbsp; 한가지 짚고 넘어가야 하는 것은, Markov assumption 처럼 i+1 번째가 i 번째에만 dependent 한 것도 autoregressive 한 것이고, 
i+1 번째가 i 번째 뿐만 아니라 <span style="color: #2454ff;">**과거의 정보들과 dependent 한 것도 autoregressive 한 것**</span>이다. 
그리고 언급했던 가정에서 볼 수 있는 것 처럼 순서의 정보가 중요해서, 모든 random varables 에 ordering 을 해야 한다. 

&nbsp; 그런데 Image 에 순서를 어떻게 적용해야 할까? MNIST 예시의 경우에서도 784개의 픽셀에 순서를 적용해야 하는데, 
실제로 어떤 방식으로 순서를 부여하느냐에 따라 성능이 달라진다. 그리고 autoregressive 가 직전의 정보만 고려할 수도 있고, 이전의 n 개를 고려할 수도 있다 
(1개만 고려하는 것을 layer 1, n 개 고려하는 것을 layer n 이라고 부른다). 즉, 어떤식으로 conditional independcy 를 부여하느냐에 따라 모델의 structure 가 달라진다. 

&nbsp; 논문을 보자. 'NADE: Neural Autoregressive Density Estimator' 로 [**이곳**](https://arxiv.org/abs/1605.02226)에서 확인할 수 있다. 
여기서 사용한 방식이 0부터 직전까지의 데이터에 dependent 하게 설계하였다. 

$$p(x_i|x_{1|i-1})\;=\sigma(\alpha_ih_i+b_i))\quad\text{where}\quad h_i\;=\;\sigma(W_{<_ix_{1:i-1}}+c)$$

그래서 첫 번째 pixel 을 어느것에도 dependent 하지 않게 만들고, 두 번째 pixel 을 첫 번째 pixel 에만 dependent 하게 만든다. 
여기서 dependent 하다는 것은, 첫 번째 pixel 의 값을 받는 Neural Network 를 만들어서, single scala 가 나온 다음에 sigmoid 를 통과시키는 것이다. 
i 번째의 pixel 은 1번부터 i-1번째까지의 pixel 과 dependent 하다. Neural Network 입장에서 생각해보면, 입력이 점차 커져서 
<span style="color: #2454ff;">**weight 가 마찬가지로 커진다**</span>.

&nbsp; NADE 는 <span style="color: #2454ff;">**explicit model**</span> 이다. 단순히 generation 만 할 수 있는 것이 아니라, 
임의의 784개의 입력 즉, binary vector 가 주어지면, 이것에 대한 <span style="color: #2454ff;">**확률을 계산**</span>할 수 있다. 
어떻게 계산할까? 

$$p(x_1,...,x_{784})\;=\;p(x_1)p(x_2|x_1)\dots p(x_{784}|x_{1:784})$$

**Joint Distribution** 을 **Chain rule** 을 통해서 분리하고, 모델이 첫 번째 pixel 에 대한 확률분포를 알고 있고, 첫 번째 pixel 이 주어졌을 때 
두 번째 pixel 에 대한 확률분포를 알고 있고 ... 다 알고 있어서 각각을 independent 하게 계산할 수 있다. 
그래서 단순히 generation 만 할 수 있는 것이 아니라, 입력에 대한 확률을 계산까지 할 수 있다.

&nbsp; 지금 예시에서는 binary pixel 이기 때문에 output 을 sigmoid 를 통과시키는데, <span style="color: #2454ff;">**continous output**</span> 
이라면 마지막 layer 에 <span style="color: #2454ff;">**Gaussian mixture 모델**</span>을 활용하여 **continous 한 distribution** 을 만들 수 있다.

<br>

&nbsp; 다음은 <span style="color: #2454ff;">**Pixel RNN**</span> 이다.<br>
Image 속 pixel 을 만드는 모델 RNN auto-regressive 모델이다. $n\times n$ Image 가 있을 때,

$$p(x)\;=\;\prod_{i=1}^{n^2}\underset{\text{Prob. i-th R}}{p(x_{i,R}|x_{<i})}\underset{\text{Prob. i-th G}}{p(x_{i,G}|x_{<i},x_{i,R})}\underset{\text{Prob. i-th B}}{p(x_{i,B}|x_{<i},x_{i,R},x_{i,G})}$$

i 번째 pixel 에 R 을 만든 뒤, G 를 만들고 마지막에 B 를 만든다. 이전 모델과 차이점이 있다면, 이전 모델은 auto-regressive 모델을 FC Layer 를 통해 만들었다. 
i 번째 pixel 은 1부터 i-1 개의 입력을 다 고려할 수 있는 Neural Network ( **Dense Layer** ) 를 만든 것인데, 
Pixel RNN 은 이름처럼 **RNN** 로 만든 것이다. 그래서 RNN 을 통해서 generate 을 하는 것이다.

한 가지 외에에는, ordering 을 어떻게 하느냐에 따라서 <span style="color: #2454ff;">**Row LSTM**</span> 과 
<span style="color: #2454ff;">**Diagonal BiLSTM**</span> 으로 나눌 수 있다. **Row LSTM** 은 R 번째 pixel 을 만들 때 **윗쪽의 정보를 활용**하는 것이고, 
**Diagonal BiLSTM** 은 Bidirectional LSTM 을 활용하되, ordering 을 했을 때 **이전 정보들을 다 활용**한다.

<br>

**Variational Auto-encoder**

&nbsp; 이제 좀더 practical 한 모델을 살펴보자.<br>
<span style="color: #2454ff;">**Latent Variable Models**</span> 이며, D. Kingma, "Variational Inference and Deep Learning: A New Synthesis" 
Ph.D. Thesis 논문으로 Adam optimizer 도 만드셨다.

그 시작으로 <u><span style="color: #2454ff;">**Variational Auto-encoder**</span></u>을 알아보자. 우선 Variational inference (VI) 를 알아야 하는데, 
이것은 <span style="color: #2454ff;">**Posterior distribution: $p_\theta(z|x)$**</span> 를 찾는 것이 목적이다. 
Posterior distribution 이란, observation 이 주어졌을 때, 관심있어 하는 random variable 의 **확률분포**이다. 

그리고 <span style="color: #2454ff;">**Variational distribution: $q_{\phi}(z|x)$**</span> 의 목적은 계산하기 어려운 posterior distribution 을 
내가 학습할 수 있는, 최적화시킬 수 있는 것으로 <span style="color: #2454ff;">**근사하는 것**</span>이다. 
그리고 그 근사하는 분포가 Variational distribution 이다.

그래서 내가 원하는 Posterior distribution 을 잘 근사할 수 있는 Variational distribution 을 찾는 일련의 과정을 
<span style="color: #2454ff;">**Variational inderence**</span> 라고 한다. 그래서 무언가를 잘 찾겠다, 최적화 하겠다 하면 **Loss function** 이 필요하다. 
Variational inference 에서는 <span style="color: #2454ff;">**KL divergence**</span> metric 을 활용해서 variational distribution 과 
posterior distribution 과의 **차이를 줄인다.**

그렇다고 하는데, 뭔지도 모르는 posterior distribution 과 어떻게 차이를 줄일까? Variational Auto-encoder 논문에 나온 
<span style="color: #2454ff;">**ELBO**</span> 를 사용하는 것이다.

$$\text{In}\;p_\theta(D)\;=\;\mathbb{E}_{q_\phi(z|x)}[\ln p_\theta(x)]$$

$$=\;\mathbb{E}_{q_\theta(z|x)}\bigg[\ln\frac{p_\theta(x,z)}{p_\theta(z|x)}\bigg]$$

$$\quad\quad\;\;=\;\mathbb{E}_{q_\phi(z|x)}\bigg[\ln\frac{p_\theta(x,z)q_\phi(z|x)}{q_\phi(z|x)p_\theta(z|x)}\bigg]$$

$$\quad\quad\quad\quad\quad\quad\quad\quad\quad\;\;=\;\mathbb{E}_{q_\phi(z|x)}\bigg[\ln\frac{p_\theta(x,z)}{q_\phi(z|x)}\bigg]
+\;\mathbb{E}_{q_\phi(z|x)}\bigg[\ln\frac{q_\phi(z|x)}{p_\theta(z|x)}\bigg]$$

$$\quad\quad\quad\quad\quad\quad\quad\quad\quad\;=\underset{\text{ELBO} \uparrow}{\mathbb{E}_{q_\phi(z|x)}\bigg[\ln\frac{p_\theta(x,z)}{q_\theta(z|x)}\bigg]}
+\;\underset{\text{Objective} \downarrow}{D_{KL}(q_\phi(z|x)||p_\theta(z|x))}$$

궁극적으로 무엇을 이야기 하냐면, Variational distribution 과 Posterior distribution 과의 KL Divergence 를 줄이는 것이 목적(Objective $\downarrow$)인데 
이것이 불가능하니깐, <span style="color: #2454ff;">**ELBO (Evidence lower bound) 를 상대적으로 높이는 것**</span>이다. 그래서 뭔지도 모르는 
posterior distribution 에 근사할 수 있다. 

ELBO 는 더 나아가 Reconstruction Term 과 Prior Fitting Term 으로 나뉘어 질 수 있다 (decomposed).

$$\underset{\text{ELBO} \uparrow}{\mathbb{E}_{q_\phi}(z|x)\bigg[\ln\frac{p_\theta(x,z)}{q_\phi(z|x)}\bigg]}\;
=\;\int\ln\frac{p_\theta(x|z)p(z)}{q_\phi(z|x)}q_\phi(z|x)dz$$

$$\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad
=\;\underset{\text{Reconstruction Term}}{\mathbb{E}_{q_\phi(z|z)}[p_\theta(x|z)]}\;-\;\underset{\text{Prior Fitting Term}}{D_{KL}(q_\theta(z|x)||p(z))}$$

여기서 Recontruction Term 을 통해 **auto-encoder** 의 <span style="color: #2454ff;">**reconstruction loss 를 최소화**</span>할 수 있고, 
Prior Fitting Term 은 latent distribution 을 <span style="color: #2454ff;">**prior distribution 과 유사**</span>하게 만든다. 
엄밀하게 따지면 explicit model 이 아닌 <span style="color: #2454ff;">**implicit model**</span> 이다.

그리고 **한계**도 존재한다.<br>
엄밀히 말하면 implicit model 이기 때문에, <span style="color: #2454ff;">**likelihood 를 계산하기 힘들다**</span>. 
그리고 ELBO 가 결국 reconstruction loss term 과 kl divergence term (prior fitting term)으로 나눠지는데, reconstruction 은 뭘 해도 되지만 
kl divergence 는 SGD 나 Adam 으로 최적화를 진행하기 때문에 <span style="color: #2454ff;">**미분가능**</span>해야 한다. 
그래서 <span style="color: #2454ff;">**diverse latent prior distribution 을 사용하기 힘들다**</span>. 
그래서 대부분의 **Variational Auto-encoder** 는 Gaussian prior 를 사용한다 
( 대부분의 경우 <span style="color: #2454ff;">**isotropic Gaussian 을 사용한다**</span> ).<br>
※ isotropic Gaussian 이란 모든 output dimension 이 independent 한 gaussian distribution 을 말한다.

$$D_{KL}(q_\phi(z|x)||\mathcal{N}(0,1))\;=\;\frac{1}{2}\sum_{i=1}^{D}(\sigma_{z_i}^2+\mu_{z_i}^2-\ln(\sigma_{z_i}^2)-1)$$

이러한 VA 를 통해 논문 속에서 얼굴을 생성한 결과를 확인할 수 있으며, 이를 통해 문장 등 여러가지를 생성할 수 있다.

<br>

**Adversarial Auto-encoder**

&nbsp; 앞에서 본 VA 의 가장 큰 단점은 **인코더**를 활용할 때, **prior fitting term** 이 **kl divergence** 를 사용한다는 것이라고 생각한다. 
그렇기 때문에 **gaussian 이 아닌 경우 활용하기 힘들다**. 그리고 많은 경우에 gaussian 을 사용하고 싶지 않을 수도 있다. 
그래서 AA (Adversarial Auto-encoder) 모델은 **GAN** 을 사용하여 latent distribution 사이의 분포를 맞춰준다. 
AA 는 VA 의 prior fitting term 속 **kl divergence** 를 <span style="color: #2454ff;">**GAN**</span> 으로 바꾼 것이라고 볼 수 있다.

그래서 <span style="color: #2454ff;">**latent distribution 을 sampling 가능한 분포만 있어도 이것과 맞출 수 있다**</span>. 
복잡하고 다양한 분포에 latent prior distribution 을 적용할 수 있다는 것이 AA 의 장점이다. Generation 성능도 VA 에 비해 좋은 경우가 많다. 

<br>

**Generative Adversarial Network**

&nbsp; 대망의 GAN 이다.

$$\underset{\text{G}}{\text{min}}\;\underset{\text{D}}{\text{max}}\;V(D,G)\;=\;\mathbb{E}_{x\sim p_{data}}(x)[\log D(x)]+\;\mathbb{E}_{z\sim p_z(z)}[\log(1-D(G(z)))]$$

GAN 의 큰 장점은, 결과로 나오는 generator 를 학습하는 <span style="color: #2454ff;">**discriminator 가 점차 좋아진다는 점**</span>인 것 같다. 
Discriminator 가 generator 를 통해서 점점 잘 되기 때문에, generator 도 같이 성능이 올라가서 좋은 이미지를 만들어낼 수 있는 것이다. 
GAN 또한 <span style="color: #2454ff;">**implicit model**</span> 이다. 

**Variational Auto-encoder** 의 경우 $p(z)$ distribution 속에서 $x$ &#10140; $p_\theta$ &#10140; $z$ &#10140; $q_\phi$ &#10140; $x$ 처럼, 
$x$ 가 인코더를 통해서 $z$ 로 갔다가 디코더를 통해서 원래 $x$ 도메인으로 가는 학습을 한다. 
그리고 generation 단계에서는 $p(z)$, latent distribution 에서 $z$ 를 샘플링해서 디코더를 통해 나오는 $x$ 가 generation 결과가 된다. 

하지만 <span style="color: #2454ff;">**GAN**</span> 은 좀 다르다.<br>
$\color{blue}z$ 라는 latent distribution 에서 출발해서 **G** 를 통해 **Fake** 가 나오고, 
**Discriminator** 는 이 **Fake** 와 **Real** 을 구분하는 분류기를 학습하고, 
**Generator** 는 그렇게 학습된 Discriminator 입장에서 True 가 나오도록 다시 generator 를 업데이트하고, 
Discriminator 는 이렇게 해서 나온 결과물들이 Real 과 discriminative 가 되도록 다시 학습한다 (D, G 를 번갈아가며 학습한다). 

**GAN Objective**

GAN Objective 는 Generator 와 Discriminator 사이의 minmax 게임으로 볼 수 있다. **Discriminator objective** 는 다음과 같다.

$$\underset{D}{\text{max}}\;V(G,D)\;=\;\mathbb{E}_{x\sim p_{data}}[\log D(x)]+\;\mathbb{E}_{x\sim p_G}[\log(1-D(x))]$$

그래서 위의 형태를 항상 **최적화** 시키는 discriminator 의 꼴은 다음과 같다.

$$D^\ast_G(x)\;=\;\frac{p_{data}(x)}{p_{data}(x)+p_G(x)}$$

Generator 가 고정되어 있을 때, 이것을 항상 최적으로 분리하는 Discriminator 는 $D^\ast_G$ 인 것이다. 
그래서 Generator 에 대해,

$$\underset{\text{G}}{\text{min}}\;V(G,D)\;=\;\mathbb{E}_{x\sim p_{data}}[\log D(x)]+\;\mathbb{x\sim p_G}[\log(1-D(x))]$$

**optimal discriminator** 를 **generator** 에 집어넣게 되면,

$$V(G,D^\ast_G(x))\;=\;\mathbb{E}_{x\sim p_{data}}\bigg[\log\frac{p_{data}(x)}{p_{data}+p_G(x)}\bigg]
+\;\mathbb{E}_{x\sim p_G}\bigg[\log\frac{p_G(x)}{p_{data}(x)+p_G{x}}\bigg]$$

$$\quad\quad\quad\quad\quad\quad\quad\;=\;\mathbb{E}_{x\sim p_{data}}\bigg[\log\frac{p_{data}(x)}{\frac{p_{data}(x)+p_G(x)}{2}}\bigg]
+\;\mathbb{E}_{x\sim p_G}\bigg[\log\frac{p_G{x}}{\frac{p_{data}(x)+P_G(x)}{2}}\bigg]-\log4$$

$$\quad\quad\quad\quad\;\;=\;\underset{2\times\text{Jenson-Shannon Divergence(JSD)}}{D_{KL}\bigg[p_{data},\frac{p_{data}+p_G}{2}\bigg]+\;D_{KL}\bigg[p_G,\frac{p_{data}+p_G}{2}\bigg]}-\log4$$

$$=\;2D_{JSD}[p_{data},p_G]-\log4$$

와 같이 된다. 이것의 의미는 <span style="color: #2454ff;">**true data distribution 과 학습한 generator 사이에 JSD 를 최소화 하는 것**</span>이다.

실제로 봤을 때, Discriminator 가 optimal discriminator 에 **수렴한다고 보장하기 힘들고**, 그렇게 됐을 때 generator 가 위의 수식처럼 나오지 않을 수도 있다. 
이론적으로는 말이 되지만, 현실적으로 JSD 줄이는 것은 의아한 부분이 있다. 

<br>

**DCGAN**

&nbsp; 처음의 GAN 은 multi layer perceptron (dense layer) 로 만들었고, Image 도메인으로 적용한 것이 DCGAN 이다. 
Deconvolutional Layer 를 가지고 generator 를 만듬으로써 성능을 높였다. 
그리고 Algorithm 적으로 좋아진 것은 없지만, **Leaky ReLU** 를 쓰는 등 여러 테크닉이 적용되었다. 

<br>

**Info-GAN**

&nbsp; 학습을 할 때, $z$ 를 통해서 단순히 Image 를 만들어내는 것이 아니라, 클래스라는 c 를 매번 랜덤하게 집어넣는다. 
random 한 one-hot vector 로 볼 수 있는데, 이를 통해 GAN 이 generate 할 때 특정 모드에 집중할 수 있게 한다. 

<br>

**Text2Image**

&nbsp; 문장이 주어지면 Image 를 생성한다. 입력이 문장이고, 이를 통해서 conditional gan 을 만들어서 Image 를 만들어내는 복잡한 네트워크를 가졌다.

<br>

**Puzzle-GAN**

&nbsp; Image 속에 subpatch 가 들어가 있으면, 이를 통해 Image 를 **복원**하는 네트워크를 GAN 을 가지고 만들었다.

<br>

**CycleGAN**

&nbsp; GAN 구조를 사용하면서, Image 사이의 도메인을 바꾼다. <span style="color: #2454ff;">**Cycle-consistency loss**</span> 를 활용한다. 
꼭 알아둬야 하는 컨셉인데, 예시로 말을 얼룩말로 바꾸려고 한다면, 똑같은 형태로 말이 있는 것과 얼룩말이 있는 이미지 2장이 필요한데, 
그럴 필요 없이 형태 구분 없이 말 사진들과 얼룩말 사진들만 있으면 된다. **GAN 구조가 2개** 들어가있는 형태이다. 

<br>

**Star-GAN**

&nbsp; 한국에서 나온 논문이고, Style Transfer 와 비슷한데 모드를 정해줄 수 있다는 점이 다르다. 즉, Image 를 조작할 수 있다는 점이 큰 특징이다. 

<br>

**Progressive-GAN**

&nbsp; 흥미로운 모델이다. **고차원의 이미지**를 잘 만들어낼 수 있는 방법론이다. $4\times4$ 라는 매우 coarse 한 Image 에서 출발해서, 
$1024\times1024$ 까지 점차 키워간다. Neural Network 에서 한 번에 고차원 Image 를 만들어내는 것이 힘드니깐, 점차 해상도를 높여가는 학습 ( **progressive training** ) 
방식을 사용했다. 

<br>

&nbsp; 이 외에도 무수히 많은 GAN 모델들이 있다. 그래서 모두 다 알기는 힘들지만, GAN 에 대한 중요한 아이디어들과, 
GAN 과 VA 가 어떻게 다르고, generate 를 하고 싶을 때 GAN 과 VA 모델 중 어떤 것을 쓸 것인지 판단할 수 있도록 학습하자.

<br>

::: details 참고
- [**Illustrated transformer (번역)**](https://nlpinkorean.github.io/illustrated-transformer/)
- [**PyTorch official Transformer tutorial**](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)
- [**1시간 만에 GAN 완전 정복하기**](https://www.youtube.com/watch?v=odpjk7_tGY0&t=69s)
- [**An Introduction to Variational Autoencoders**](https://arxiv.org/abs/1906.02691)
:::

<br>

<style scoped>
.tags { color: #2454ff; }
a { color: #2454ff; }
</style>