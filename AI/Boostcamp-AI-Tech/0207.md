---
title: 02/07 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 02/07 Summary
  - property: og:title
    content: 02/04 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 02/07 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0207.html
---

### 2022/02/07, 새로 알게된 점

<p class="tags">#Deep_Learning #Optimization #Gradient_Descent_Methods #Regularization</p>

&nbsp; 오늘은 Deep Learning 역사부터 학습 전반에 관한 내용을 배웠다.

#### History

&nbsp; Deep Learning's Most Important Ideas - A Brief Historical Review (Denny Britz, 2020) 논문에서 나온 내용을 바탕으로 살펴보았다.

1. **2012** - **AlexNet**

    - 224 x 224 이미지를 분류하는 대회에서 처음으로 딥러닝 모델로 1등을 달성하였고, 그 이후부터는 딥러닝 모델로만 우승하였다.
    AlexNet 은 Multi-GPU 를 사용한 모델로 한 번 살펴본 적이 있다.

2. **2013** - **DQN**

    - 딥마인드에서 고안한 **강화 학습**으로, Q-Learning 이라는 강화 학습 방법론을 딥러닝에 접목시켰다.

3. **2014** - **Encoder/Decoder, Adam**

    - Encoder/Decoder 의 경우 NMT 를 해결하기 위해 고안되었다.

    - 나중에 언급할 Gradient Descent Methods 에 나올 내용이지만, Adadelta 의 EMA 장점과 Momentum 의 장점을 합쳤다. 
    학습 시 기본적으로 사용할 Optimizer 이다.

4. **2015** - **GAN, ResNet**

    - Generator(생성자) 와 Discriminator(구분자) 서로 대립(Adversarial)하며 성능을 개선해 나가는 방향으로 학습하는, 
    생성모델로 새로운 패러다임을 열었다.

    - 딥러닝이지만 Gradient Vanishing 문제로 Layer 를 많이 쌓을 수 없었지만, ResNet 에서는 Skip Connection 개념을 이용하여 문제점을 어느정도 극복하여, 
    Layer 를 더 쌓을 수 있었다.

5. 2016

6. **2017** - **Transformer**

    - Google 낸 **'Attention Is All You Need'** 란 도전적인 논문에서 고안한 모델로, CNN, RNN, LSTM 등을 사용하지 않고 
    attention 을 multi-head 방식으로 사용하여 Encoder/Decoder Layer 를 쌓았다. 그 성능이 현저히 좋아, 최근 대부분의 모델들은 
    transformer 가 바탕이 되고 있다.

7. **2018** - **Bert**

    - Bidirectional Encoder Representation from Transformers 의 약자로, 자연어를 이해하기 위해 양방향 학습을 지원한다. 
    주로 HuggingFace 에 있는 Pre-trained 된 모델을 이용한다.

8. **2019** - **Big Language Models** (**GPT-X**)

9. **2020** - **Self-Supervised Learning**

    - 한정적인 데이터를 넘어서, 라벨링이 되지않은 데이터를 비지도 학습으로 사용하는 개념으로, **SimCLR** 과 **BYOL** 등이 유명하다.

    - 다른 방향으로 Self-Supervised Data Sampling 이 있는데, 특정 도메인에 대해 잘 알고 있어서, 해당 지식을 바탕으로 데이터셋을 제작하는 기법이다.

<br>

&nbsp; 간단하게 역사를 살펴봤으니, 이제 딥러닝 개념에 대해 알아볼 시간이다. 우선 딥러닝의 이미지를 쉽게 그리기 위해 **데이터**, **모델**, **Loss**, 
그리고 **Algorithm** 관점으로 나눠보면 좋다.

#### Linear Neural Networks

&nbsp; 가장 간단한 구조를 생각해보자. 1차원 데이터가 N개 존재하고, 1차원 결과에 맞도록 모델링 해야 한다. 그래서 일차 방정식을 떠올릴 수 있다.

$$\hat{y}\;=\;wx\;+\;b$$

데이터에 잘 맞는 함수가 되도록 파라미터를 찾으려면 어떻게 해야할까? 어느정도 차이가 나는지 수치화한 것을 Loss 라고 한다. 지금 드는 예시에서는 
MSE 라는 Loss Function 을 사용한다.

$$\text{loss}\;=\;\frac{1}{N}\sum^{N}_{i=1}(y_i\;-\;\hat{y}_i)^2$$

그리고 실제 값과 예측 값의 차이가 작도록, Loss 를 줄여야 하고, 그래서 Loss 를 편미분하여 **- 방향**으로 향하도록 하는 Weight 와 Bias 값을 구한다.

**Weight**

$$\frac{\partial\text{loss}}{\partial w}\;=\;\frac{\partial}{\partial w}\frac{1}{N}\sum_{i=1}^{N}(y_i\;-\;\hat{y}_i)^2$$

$$\quad\quad\quad\quad\quad\quad=\;\frac{\partial}{\partial w}\frac{1}{N}\sum_{i=1}^{N}(y_i\;-\;wx_i\;=\;b)^2$$

$$\quad\quad\quad\quad\quad\quad\quad=\;-\frac{1}{N}\sum_{i=1}^{N}-2(y_i\;-\;wx_i\;-\;b)x_i$$

**Bias**

$$\frac{\partial\text{loss}}{\partial b}\;=\;\frac{\partial}{\partial b}\frac{1}{N}\sum_{i=1}^{N}(y_i\;-\;\hat{y}_i)^2$$

$$\quad\quad\quad\quad\quad\quad=\;\frac{\partial}{\partial b}\frac{1}{N}\sum_{i=1}^{N}(y_i\;-\;wx_i\;=\;b)^2$$

$$\quad\quad\quad\quad\quad\quad\;=\;-\frac{1}{N}\sum_{i=1}^{N}-2(y_i\;-\;wx_i\;-\;b)$$

이러한 과정을 반복하여 파라미터를 업데이트한다. 이러한 과정을 <span style="color: #2454ff;">**Gradient Descent**</span> 라고 부른다.

$$w\quad\leftarrow\quad w\;-\eta\frac{\partial\text{loss}}{\partial w}$$

$$b\quad\leftarrow\quad b\;-\;\eta\frac{\partial\text{loss}}{\partial b}$$

여기서 $\eta$ 는 Step Size 로, Learning rate 을 의미한다.

여기까지가 **1차원 &#10140; 1차원** 학습 방법이었다. 그렇다면 **N 차원 &#10140; M 차원**은? 행렬을 이용하면된다. 일종의 선형 변환인 셈이다.

$$y\;=\;W^Tx\;+\;b$$

**딥러닝**은, 이러한 것(layer)을 **여러번 쌓은 것**이다.

$$y\;=\;W_2^Th\;=\;W_2^TW_1^Tx$$

하지만 단순히 곱만 하게 되면 선형성을 벗어나지 못하므로, 
layer 와 layer 사이에 활성화 함수라는 비선형성을 추가해줘야 딥러닝이 의미를 가지게 된다.

$$y\;=\;W_2^Th\;=\;W_2^T{\color{red}\rho}\;(W_1^Tx)$$

위의 $\rho$ 에 해당하는 활성화 함수로는 ReLU, Sigmoid, Hyperbolic Tangent 등이 있다.

<br>

&nbsp; 다시 되돌아가서 Loss Function 을 **MSE** 로 사용한 것에 이유를 생각해보자. 예측값과 실제값의 차이를 따진다면, 제곱이 아니라 네제곱이어도 될 것 같고, 
**절댓값**을 사용해도 될 것 같다. 맞다. 사용해도 된다. 하지만 그 결과가 달라진다.

&nbsp; 데이터에 이상치가 없이 이상적인 값들만 있다면 네제곱을 사용해도 된다. 하지만 그만큼의 컴퓨팅 자원이 소모된다. (세제곱은 부호가 바뀐다.) 
그리고 데이터에 이상치 즉, 노이즈가 많다면 어떨까? 제곱에 의해 그 차이가 커져서, 전반적인 학습이 
이상하게 된다. 이런 경우 절댓값 방식을 사용하면, 이상치에 조금 **덜 민감**(**robust**)해진다.

&nbsp; 이러한 방식으로, **데이터의 성격**, 달성하고자 하는 **목표**에 따라 Loss function 을 적절히 선택해야 한다. 
일반적으로 회귀에는 <span style="color: #2454ff;">**MSE**</span>, 분류에는 <span style="color: #2454ff;">**CE**</span>, 기타 확률 모델 접근에는 <span style="color: #2454ff;">**MLE**</span> 등을 사용한다지만, 
무작정 암기식으로 쓰지 말고 이해를 하고 쓰려고 노력하자.

<br>

#### Optimization

&nbsp; 다음으로 최적화 방법에 대해 살펴보자. 우선 대부분의 경우 **일반화**(**Generalization**) 성능을 높이는 것이 목표이다. 
이것은 Training Erorr 와 Testing Error 의 차이로, 비슷하게 유지되는 것이 가장 좋다. 
일반화의 성능을 높이기 위해 <span style="color: #2454ff;">**Cross Validation**</span>, <span style="color: #2454ff;">**Boostraping**</span>, 
<span style="color: #2454ff;">**Bagging**</span>, 그리고 <span style="color: #2454ff;">**Boosting**</span> 등의 전략을 사용한다.

&nbsp; 첫 번째로 <span style="color: #2454ff;">**Cross Validation**</span> 이다. 학습데이터를 Train / Test 로 나눈 뒤 Train 에 대해 <span style="color: #2454ff;">**K 개로 나누는 것**</span>이다. (**K-Fold**) 
그래서 K-1 개를 Train 데이터로, 1 개를 Valid 데이터로 사용하는데, 사용되는 경우를 바꿔가며 나온 각각의 값을 평균내서 사용한다. 
그렇게 되면 일반적으로 일반화 성능이 좋아진다. &#10140; Test 에서도 유사한 성능을 낼 것이라고 예상할 수 있다.

&nbsp; 추가적으로, Time Series 데이터에 대해서는 K-Fold 를 어떻게 사용할까? 위에 언급한 방식으로 그대로 적용하면 될까? 답은 **아니오**이다. Time Series 는 이름 처럼 
<span style="color: #2454ff;">**순서 정보가 중요**</span>하고, 대부분의 경우 미래의 값을 예측한다. 
그런데 K-Fold 를 그대로 적용하게 되면 미래의 값을 이용하여 과거를 예측하도록 학습하는 꼴이 된다. 
그래서 <span style="color: #2454ff;">**Nested Cross-Validatoin**</span> 을 이용한다. 매번 같은 크기의 K-Fols 를 사용하는 것이 아니다. 
Time Series 데이터를 K+1개로 나눴을 때, 1번째 데이터를 학습시키고 2번째 데이터를 Validaiont 용으로, 그리고 3번째를 Testing 으로 사용한다. 그 다음에는 
1~2번째 데이터를 학습시키고 3번째 데이터를 Validation 용으로, 그리고 4번째는 Testing 으로 사용한다. 이런 방식으로 <span style="color: #2454ff;">**Sequence 정보가 유실되지 않도록 K-Fold 를 사용**</span>한다.

&nbsp; 두 번째로 <span style="color: #2454ff;">**Bootstrapping**</span> 이다. 데이터의 일부만 사용하는 모델을 여러개 만들고, 해당 모델들의 metric 을 활용하는 방식을 말한다.

&nbsp; 세 번째로 <span style="color: #2454ff;">**Bagging**</span> 이다. Boostrapping 방식의 연장선으로, 여러 모델들에 대해 나온 값에 평균을 취하너가 Voting 을 이용하여 값을 도출하는 방식을 말한다.

&nbsp; 마지막으로 <span style="color: #2454ff;">**Boosting**</span> 이다. 이전과는 다르게, 간단한 모델을 만든다. 그리고 학습을 시켰을 때, 모델이 간단하보니 잘 예측하지 못하는 데이터가 존재할 것이다. 
그런 경우 해당 데이터들에 대해서만 잘 예측하도록 모델을 추가적으로 만든다. 이러한 방식으로 모델을 추가하고, 최종적으로 모든 모델들을 sequential 하게 합치는 방식이다.

<br>

#### Gradient Descent Methods

&nbsp; GD 흐름을 언급하기에 앞서서 <span style="color: #2454ff;">**Batch Size**</span> 와 관련한 
**On Large-batch Training for Deep Learning: Generalization Gap and Sharp Minima, 2017** 논문에 대해서 이야기 해보고자 한다. 
해당 논문에서는 **Large Batch Size** (512 ~) 로 학습할 경우 <span style="color: #2454ff;">**Sharp Minimizer**</span> 에 도달하는 경향이 있고, 
**Small Batch Size** 로 학습할 경우 <span style="color: #2454ff;">**Flat Minimizer**</span> 에 도달하는 경향이 있다고 말한다. 
그렇게 되면, Sharp Minimum 의 경우에 Generalization Gap 이 클 경우 성능이 빠르게 나빠질 수 있는 반면, Flat Minimum 의 경우에는 Generalization Gap 이 크더라도 
두드러지는 성능 악화가 잘 나타나지 않는다고 한다. 즉, <span style="color: #2454ff;">**Small Batch Size**</span> 를 사용하는 것이 <span style="color: #2454ff;">**일반적으로 성능이 좋다**</span>고 한다.

<br>

1. **Stochastic Gradient Descent**

    $$W_{t+1}\quad\leftarrow\quad W_t\;-\;\overset{\text{Learning Rate}}{\color{red}\eta} \underset{\text{Gradient}}{\color{blue}{g_t}}$$

    - 전체 데이터 학습시, 고정된 분포로 인해 **local minimum 탈출하기 힘들다는 단점을 극복**하기 위해 **확률적으로 데이터를 샘플링**하여, 매 에폭마다 변화하는 분포 속에서 local minimum 을 탈출하는 전략이다. 
    하지만 learning rate 를 설정하는 것이 어렵다는 단점이 있다.

<br>

2. **Momentum**

    $$\overset{\text{accumulation}}{\color{red}{a_{t+1}}}\quad\leftarrow\quad\overset{\text{momentum}}{\color{blue}\beta} a_t\;+\;g_t$$

    $$W_{t+1}\quad\leftarrow\quad W_t\;-\;\eta \color{red}{a_{t+1}}$$

    - 이름처럼 관성을 적용하여 흘러간 방향을 어느정도 유지시켜주기 때문에, local minimum 에서 탈출할 가능성이 있다. 하지만 반대로 **local minimum 에 잘 수렴하지 못한다는 단점**이 있다.

<br>

3. **Nesterov Accelerated Gradient**

    $$a_{t+1}\quad\leftarrow\quad\beta a_t\;+\;\overset{\text{Lookahead gradient}}{\color{red}{\nabla\mathcal{L}(W_t\;-\;\eta\beta a_t)}}$$

    - Momentum 의 단점을 극복하기 위해, 현재 위치의 미분 값을 사용하는 Momentum 방식이 아닌, **해당 방향으로 가보고 그 지점의 미분을 계산**한다. 그래서 Momentum 에 비해 
    **local minimum 에 빨리 수렴**한다는 장점이 있다.

<br>

4. **Adagrad**

    $$W_{t+1}\;=\;W_t\;-\;\frac{\eta}{\sqrt{\underset{\text{Sum of gradient squares}}{\color{blue}{G_t}}\;+\;\underset{\text{for numerical stability}}{\color{red}\epsilon}}}$$

    - 기본의 방식과는 다르게, **파라미터가 많이 변화했는지를 확인**한다. 많이 변화한 파라미터에 대해서는 적게 변화시키고, 적게 변화한 파라미터에 대해서는 많이 변화시킨다. 
    식에서 보이는 것 처럼, **오랜 기간 학습 시** 분모에 있는 $G_t$ 의 값이 매우 커져 결과적으로 작아져서, **파라미터 업데이트가 안된다.**

<br>

5. **Adadelta**

    $$\overset{\text{EMA of gradient squares}}{\color{blue}{G_t}}\;=\;\gamma G_{t-1}\;+\;(1\;-\;\gamma)g_t^2$$

    $$W_{t+1}\;=\;W_t\;-\;\frac{\sqrt{H_{t-1}\;+\;\epsilon}}{\sqrt{\color{blue}{G_t}}\;+\;\epsilon}g_t$$

    $$\underset{\text{EMA of difference squares}}{\color{red}{H_t}}\;=\;\gamma H_{t-1}\;+\;(1\;-\;\gamma)(\nabla W_t)^2$$

    - 오랜 기간 학습 시 파라미터 업데이트가 안된다는 Adagrad 의 단점을 해결하기 위해, **t 라는 구간 동안에 대해서만 adagrad 를 적용**한다. 
    하지만 모델의 사이즈가 매우 커서 파라미터 개수가 무수히 많다면, t 구간에 대해 해당 파라미터를 모두 누적해서 가지고 있기에는 램이 감당할 수 없다. 
    그래서 **Exponential Moving Average** 를 이용하여 t 구간에 대한 평균 값을 가지고 있는다.

    - **Learning rate 가 없다는 특징**이 있지만, 크게 조작할 만한 하이퍼파라미터가 없어서 많이 사용하지는 않는다.

<br>

6. **RMSprop**

    $$\overset{\text{EMA of gradient squares}}{\color{blue}{G_t}}\;=\;\gamma G_{t-1}\;+\;(1\;-\;\gamma)g_t^2$$

    $$W_{t+1}\;=\;W_t\;-\;\frac{\overset{\text{stepsize}}{\color{red}\eta}}{\sqrt{{\color{blue}{G_t}}\;+\;\epsilon}}$$

    - 분모에 EMA 를 넣는 것은 Adadelta 와 유사하지만, 분자에 stepsize 가 들어간다는 점이 다르다. 성능이 괜찮게 나와서 많이 사용했었다.

<br>

7. **Adam**

    $$\overset{\text{Momentum}}{\color{red}{m_t}}\;=\;\beta_1m_{t=1}\;+\;(1\;-\;\beta_1)g_t$$

    $$\overset{\text{EMA of gradient squares}}{\color{blue}{v_t}}\;=\;\beta_2v_{t-1}\;+\;(1\;-\;\beta_2)g_t^2$$

    $$W_{t+1}\;=\;W_t\;-\;\frac{\eta}{\sqrt{\color{blue}{v_t}\;+\;\epsilon}}\frac{\sqrt{1\;-\;\beta_2^t}}{1\;-\;\beta_1^t}\color{red}{m_t}$$

    - 가장 무난히 사용되는 방식이며, 많은 경우에 대해 좋은 성능을 보인다. Adadelta 의 EMA 라는 장점과 Momentum 방식을 이용한다. (Adaptive Momentum Estimation)

    - 사용되는 하이퍼파라미터로는 <span style="color: #2454ff;">**$\beta_1$**</span> (momentum 을 얼마나 유지시킬 지), <span style="color: #2454ff;">**$\beta_2$**</span> 
    (gradient square 에 대한 EMA 정보), <span style="color: #2454ff;">**$\eta$**</span> (learning rate), 그리고 
    <span style="color: #2454ff;">**$\epsilon$**</span> (분모가 0이 되게 막는 것) 이 있다. $\epsilon$ 은 대게 $10^{-7}$ 근처의 값으로 설정하는데, 
    **이 값을 잘 바꾸는 것이 생각보다 practical 하게 중요하다.**

<br>

#### Regularization

&nbsp; 마지막으로 <span style="color: #2454ff;">**정규화**</span> 방법이다. 이것 또한 Generalization 을 잘 되게 하는 것으로 **학습을 방해하는 것**이다. 
학습을 방해함으로써, 학습 데이터 뿐만 아니라 다른 **일반적인 데이터에 대해서도 성능이 잘 나오도록 학습**시킨다.

1. **Early Stopping**

    - Validation Error 가 낮아지다가 높아지는 시점이 오면 직전에 종료시켜 Generalization Gap 을 최소화한다. (Test 로 판단하면 안된다!)

<br>

2. **Parameter Norm Penalty**

    $$\text{total cost}\;=\;\text{loss}(\mathcal{D};\;\mathcal{W})\;+\;\overset{\text{Parameter Norm Penalty}}{\frac{\alpha}{2}||W||_2^2}$$

    - 파라미터가 너무 **커지지 않게 하는 것** 이다. (부호 상관없이 크기 관점)

    - 부드러운 함수일 수록 generalization 성능이 좋을 것이라는 가정 하에, Neural Network 가 만들어내는 함수의 공간 속에서 최대한 **함수를 부드럽게 만드는 것**이다.

    - 이 방식을 **Weight Decay** 라고 부르기도 한다.

<br>

3. **Data Augmentation**

    - 라벨링의 의미를 잃지 않는 선에서, 기존 데이터에 변형을 가하며 데이터의 절대적인 양을 늘리는 작업이다. 좌우로 기울이기, 좌우 반전, 상하 반전(경우에 따라 조심 ex. 9 &#10140; 6), 
    등이 있다. 이런 저런 방식을 적용하면 기존 데이터를 10배 가량 부풀릴 수 있을 것 같다. 하지만 데이터의 품질이 떨어지지 않도록 항상 주의해야 한다.

    - **Noise Robustness**

        - 왜 잘되는지에 대한 설명은 없지만, <span style="color: #2454ff;">**데이터**</span>나 <span style="color: #2454ff;">**Weights**</span> 에 
        <span style="color: #2454ff;">**노이즈**</span>를 추가시켜 학습하면 성능이 좋아진다.

    - **Label Smoothing**

        - 복수의 데이터를 섞는 작업이다. 적은 코드 대비 큰 성능 향상을 꾀할 수 있다.

        - <span style="color: #2454ff;">**Mixup**</span>

        - <span style="color: #2454ff;">**Cutout**</span>

        - <span style="color: #2454ff;">**CutMix**</span>

<br>

4. **Dropout**

    - 랜덤하게 weight 을 0으로 만들어 학습시키고, 추론시에는 원래대로 되돌린다. 수학적으로 증명되진 않았지만, 데이터를 robust 하게 학습하여 성능이 좋아진다고 알려져있다.

<br>

5. **Batch Normalization**

    $$\mu_B\;=\;\frac{1}{m}\sum_{i=1}^{m}x_i$$

    $$\sigma^2_B\;=\;\frac{1}{m}\sum_{i=1}^{m}(x_i\;-\;\mu_B)^2$$

    $$\hat{x}_i\;=\;\frac{x_i\;-\;\mu_B}{\sqrt{\sigma^2_B\;+\;\epsilon}}$$

    - 논문 **Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 2015** 에서 나온 내용이다. 
    적용시키고자 하는 Layer 의 <span style="color: #2454ff;">**Statistics 를 정규화**</span>한다. Internal Covariate Shift 를 줄임으로써 학습이 잘 된다고 하는데, 
    이 내용에 대해 논란이 많다. 하지만 **이 방식을 적용하여 Layer 를 쌓을 시 학습이 잘되긴 한다.**

    - <span style="color: #2454ff;">**Batch Norm**</span>, <span style="color: #2454ff;">**Layer Norm**</span>, 
    <span style="color: #2454ff;">**Instance Norm**</span>, <span style="color: #2454ff;">**Group Norm**</span> 이렇게 4가지 방식이 존재하므로, 
    Batch Normalization 을 사용한다면 4가지 방법을 바꿔가며 성능이 좋은 것을 사용해보자.

<br>

<hr>

### 피어 세션

추후에 진행할 Image Classification 대회에 Data Augmentation 을 적용시킬 생각에 벌써부터 설렌다..

<br>

<br>

<br>

<style scoped>
.tags { color: #2454ff; }
a { color: #2454ff; }
</style>