---
title: 01/21 Summary
lang: ko-KR

meta:
  - name: description
    content: 부스트캠프 AI Tech 01/21 Summary
  - property: og:title
    content: 01/21 Summary
  - property: og:description
    content: 부스트캠프 AI Tech 01/21 Summary
  - property: og:image
    content: 'https://boostcamp.connect.or.kr/images/pavicon_180_v2.ico'
  - property: og:url
    content: https://leedooho.com/AI/Boostcamp-AI-Tech/0121.html
---

### 2022/01/21, 새로 알게된 점

<p class="tags">#조건부확률 #기대값 #몬테카를로 #중심극한정리 #MLE #쿨백-라이블러 #베이즈정리</p>

#### 딥러닝 확률론

&nbsp; 딥러닝은 확률론 기반의 기계학습 이론에 바탕을 두기 때문에, **손실함수**는 **데이터 공간을 통계적으로 해석**해서 유도한다. 
회귀분석의 $L_2$ norm 은 <span style="color: #2454ff;">**예측 오차의 분산을 최소화**</span>하는 방향으로 학습하도록 유도하며, 
분류의 교차엔트로피는 <span style="color: #2454ff;">**예측의 불확실성을 최소화하는 방향**</span>으로 학습을 유도한다.

#### 기대값

&nbsp; **기대값**(**expectation**)은 데이터를 대표하는 통계량으로, 데이터를 분석하는 데 사용 가능한 다양한 **통계적 범함수를 계산**하는데 사용된다. 
기대값을 이용해 **분산, 첨도, 공분산** 등을 계산할 수 있다. 더 나아가 회귀 문제에서 **조건부기대값** $\mathbb{E}[y|x]$ 을 추정한다.

$$\mathbb{E}_{x\;\sim\;P(x)}[f(x)]\;=\;\underset{\text{연속확률분포}}{\int_{\mathcal{X}}f(x)P(x)dx}\quad\quad
\mathbb{E}_{x\;\sim\;P(x)}[f(x)]\;=\;\underset{\text{이산확률분포}}{\sum_{x\in\mathcal{X}}f(x)P(x)}$$

<br>

$$\mathbb{V}(x)\;=\;\mathbb{E}_{x\;\sim\;P(x)}[(x-\mathbb{E}[x])^2]$$

$$\text{Skewness}(x)\;=\;\mathbb{E}\Bigg[\bigg(\frac{x-\mathbb{E}[x]}{\sqrt{\mathbb{V}(x)}}\bigg)^3\Bigg]$$

$$\text{Cov}(x_1,\;x_2)\;=\;\mathbb{E}_{x_1,x_2\;\sim P(x_1,x_2)}[(x_1-\mathbb{E}[x_1])(x_2-\mathbb{E}[x_2])]$$

#### 몬테카를로 샘플링

&nbsp; 하지만 대부분의 기계학습 문제의 경우 확률분포를 모른다.<br>
그래서 <span style="color: #2454ff;">**몬테카를로 샘플링을 통해 데이터를 이용하여 기대값을 계산**</span>할 수 있다. 
이는 이산형, 연속형 상관없이 성립한다! <span style="color: #2454ff;">**독립추출**</span>만 보장되면 **대수의 법칙**(law of large number)에 의해 수렴성을 보장한다.

$$\mathbb{E}_{x\sim P(x)}[f(x)]\;\approx\;\frac{1}{N}\sum^{N}_{i=1}f(x^{(i)})\quad\quad x^{(i)}\;\overset{\text{i.i.d.}}{\sim}\;P(x)$$

※ &nbsp; **i.i.d.** &nbsp; &#10140; &nbsp; 각각 임의의 변수들이 독립적이며 동일한 확률변수를 가지는 분포를 뜻한다.

#### 모수, 그리고 MLE

&nbsp; 모수는 모집단의 특성을 나타내는 값으로, 실제로는 알 수 없어 추정해야 한다. 
그래서 <span style="color: #2454ff;">**적절한 가정 위에서 확률분포를 추정**</span>하는 것이 목표이다. 
기계학습의 경우 특정 확률분포를 가정한다기 보단, 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는 
<span style="color: #2454ff;">**비모수(nonparametric) 방법론**</span>에 속한다.

히스토그램 모양 관찰을 통해 아래와 같이 확률분포를 가정할 수 있으며, <span style="color: #2454ff;">**검증은 필수**</span>이다.

- 데이터가 이진 값(0 or 1)만 가짐 &nbsp; &#10140; &nbsp; 베르누이분포
- 데이터가 이산적인 값을 가짐 &nbsp; &#10140; &nbsp; 카테고리분포
- 데이터가 [0, 1] 사이에서 값을 가짐 &nbsp; &#10140; &nbsp; 베타분포
- 데이터가 0 이상의 값을 가짐 &nbsp; &#10140; &nbsp; 감마분포, 로그정규분포
- 데이터가 $\mathbb{R}$ 에서 값을 가짐 &nbsp; &#10140; &nbsp; 정규분포, 라플라스분포
- etc.

확률분포를 가정했다면 아래의 식으로 모수를 추정해볼 수 있다. (정규분포 기준)

$$\overset{\text{표본평균}}{\bar{X}\;=\;\frac{1}{N}\sum^{N}_{X_i}}\quad\quad
\overset{\text{표본분산}}{S^2\;=\;\frac{1}{N-1}\sum^{N}_{i=1}(X_i-\bar{X})^2}$$

<br>

$$\mathbb{E}[\bar{X}]\;=\;\mu\quad\text{정규분포 평균}\quad\quad\quad\quad\mathbb{E}[S^2]\;=\;\sigma^2\quad\text{정규분포 분산}$$

※ 통계량의 확률분포를 <span style="color: #2454ff;">**표집분포**</span>(**sampling distribution** $\neq$ sample distribution)라고 부르며, 
표본평균의 표집분포는 $N$ 이 커질수록 정규분포 $\mathcal{N}(\mu,\;\sigma^2/N)$ 를 따른다. &#10140; <span style="color: #2454ff;">**중심극한정리**</span>(Central Limit Theorem)

&nbsp; 하지만 가정이 틀리다면 다른 확률분포를 가정해야 하고, 또한 다른 통계량을 사용해야 한다. 다양한 가정이 있을 수 있고, 또한 틀릴 수 있는데 
앞으로는 이론적으로 가장 가능성이 높은 모수를 추정하는 방법 중 하나인 <span style="color: #2454ff;">**최대가능도 추정법**</span>(Maximum Likelihood Estimation, MLE)를 사용한다.

$$\hat{\theta}_{MLE}\;=\;\underset{\theta}{\text{argmax}}\;L(\theta;x)\;=\;\underset{\theta}{\text{argmax}}\;P(x|\theta)$$

데이터 집합 $X$ 가 <span style="color: #2454ff;">**독립적으로 추출되었다면 로그가능도를 최적화**</span>한다. 
로그가능도를 사용함으로써, 연산량을 $O(n^2)$ 에서 $O(n)$으로 낮출 수 있다.

#### 쿨백-라이블러

&nbsp; 손실함수는 데이터의 확률분포와 학습하는 확률분포의 거리를 통해 유도한다. 여기서 '거리'는 다음과 같은 함수를 이용하여 계산한다.

- 총변동 거리 (Total Variation Distance, TV)
- 쿨백-라이블러 발산 (Kullback-Leibler Divergence, KL)
- 바슈타인 거리 (Wasserstein Distance)

그중에서 쿨백-라이블러 발산에 대해 알아보자.

$$\mathbb{KL}(P||Q)\;=\;\overset{\text{이산확률변수}}{\sum_{x\in\mathcal{X}}P(X)\log}\Bigg(\frac{P(x)}{Q(X)}\Bigg)\quad\quad
\mathbb{KL}(P||Q)\;=\;\overset{\text{연속확률변수}}{\int_{\mathcal{X}}P(X)\log}\Bigg(\frac{P(X)}{Q(X)}\Bigg)dx$$

<br>

이는 다음과 같이 분해할 수 있다.

<br>

$$\mathbb{KL}(P||Q)\;=\;-\underset{크로스 엔트로피}{\mathbb{E}_{x\sim P(X)}[\log Q(X)]}\;+
\underset{\text{엔트로피}}{\mathbb{E}_{X\sim P(X)}[\log P(X)]}$$

따라서 분류 문제에서는 $P$ 를 정답레이블로, $Q$ 를 모델 예측이라고 하면, MLE 추정법은 <span style="color: #2454ff;">**쿨백-라이블러 발산을 최소화**</span>하는 것과 같다.

#### 베이즈 정리

&nbsp; 베이즈 정리는 조건부확률을 이용하여 <span style="color: #2454ff;">**정보를 갱신하는 방법**</span>이다. 
새로운 데이터가 들어왔을 때, 이전의 사후확률이 새로운 사전확률로 사용하여 <span style="color: #2454ff;">**새로운 사후확률**</span>을 계산할 수 있다.

$$\underset{\underset{\text{posterior}}{\text{사후확률}}}{P(\theta|\mathcal{D})}\;
=\;\underset{\underset{\text{prior}}{\text{사전확률}}}{P(\theta)}\frac{\overset{\text{가능도}}{P(\mathcal{D}|\theta)}}{\underset{\text{Evidence}}{P(\mathcal{D})}}$$

여기서 사용되는 조건부 확률은 유용하지만 <span style="color: #2454ff;">**인과관계 추론**</span>시에는 함부로 사용하면 안된다. 
인과관계를 알아내기 위해서는 <span style="color: #2454ff;">**중첩요인(confounding factor)의 효과를 제거**</span>하고 원인에 해당하는 변수만의 인과관계를 계산해야 한다.<br>
&#10140; 조정(intervention) 효과를 통해 $Z$ 의 개입을 제거한다.

<br>

<hr>

### 피어 세션

AI로 딥다이브를 하기 위해 논문을 꾸준히 읽어야겠다는 생각이 들었다.

그 시작을 `attention` 으로 하고, 이후의 timeline 에 따라 이어서 읽을 계획이다.

<br>

<br>

<br>

<style scoped>
.tags { color: #2454ff; }
a { color: #2454ff; }
</style>